{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before you start, the env setup \n",
    "1. use conda to create a new env\n",
    "```bash\n",
    "    conda create -n nmbe python=3.7\n",
    "    conda activate nmbe\n",
    "```\n",
    "\n",
    "2. install the following packages\n",
    "```bash\n",
    "    pip install torch==1.10.0\n",
    "    pip install sacremoses==0.0.41\n",
    "    pip install transformers\n",
    "```\n",
    "```bash if using cuda\n",
    "    pip install torch==1.10.0.1+cu113 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "    pip install sacremoses==0.0.41\n",
    "    pip install transformers\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # About this notebook\n",
    " - Deberta-base starter code\n",
    " - pip wheels is [here](https://www.kaggle.com/yasufuminakama/nbme-pip-wheels)\n",
    " - Inference notebook is [here](https://www.kaggle.com/yasufuminakama/nbme-deberta-base-baseline-inference)\n",
    "\n",
    " If this notebook is helpful, feel free to upvote :)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Directory settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Directory settings\n",
    "# ====================================================\n",
    "import os\n",
    "\n",
    "root = '.'\n",
    "OUTPUT_DIR = root + '/'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# CFG (Classifier Free Guidance?)\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    wandb=False\n",
    "    #competition='NBME'\n",
    "    #_wandb_kernel='nakama'\n",
    "    debug=False\n",
    "    apex=True\n",
    "    print_freq=100\n",
    "    num_workers=4\n",
    "    model=\"microsoft/deberta-base\"\n",
    "    scheduler='cosine' # ['linear', 'cosine']\n",
    "    batch_scheduler=True\n",
    "    num_cycles=0.5\n",
    "    num_warmup_steps=0\n",
    "    epochs=5\n",
    "    encoder_lr=2e-5\n",
    "    decoder_lr=2e-5\n",
    "    min_lr=1e-6\n",
    "    eps=1e-6\n",
    "    betas=(0.9, 0.999)\n",
    "    batch_size=12\n",
    "    fc_dropout=0.2\n",
    "    max_len=512\n",
    "    weight_decay=0.01\n",
    "    gradient_accumulation_steps=1\n",
    "    max_grad_norm=1000\n",
    "    seed=42\n",
    "    n_fold=5\n",
    "    # possible to simply delete folds that are already trained\n",
    "    trn_fold=[0, 1, 2, 3, 4]\n",
    "    train=True\n",
    "    \n",
    "if CFG.debug:\n",
    "    CFG.epochs = 2\n",
    "    CFG.trn_fold = [0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11512\\2484325780.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pip uninstall -y transformers'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'python -m pip install --no-index --find-links=./input/nbme-pip-wheels transformers'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtokenizers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import ast\n",
    "import copy\n",
    "import gc\n",
    "import itertools\n",
    "import json\n",
    "import math\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import joblib\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GroupKFold, KFold, StratifiedKFold\n",
    "from torch.nn import Parameter\n",
    "from torch.optim import SGD, Adam, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "os.system('pip uninstall -y transformers')\n",
    "os.system('python -m pip install --no-index --find-links=./input/nbme-pip-wheels transformers')\n",
    "import tokenizers\n",
    "import transformers\n",
    "\n",
    "print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n",
    "print(f\"transformers.__version__: {transformers.__version__}\")\n",
    "from transformers import (AutoConfig, AutoModel, AutoTokenizer,\n",
    "                          get_cosine_schedule_with_warmup,\n",
    "                          get_linear_schedule_with_warmup)\n",
    "\n",
    "%env TOKENIZERS_PARALLELISM=true\n",
    "\n",
    "device = \"cpu\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_scaler = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Helper functions for scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://www.kaggle.com/theoviel/evaluation-metric-folds-baseline\n",
    "\n",
    "def micro_f1(preds, truths):\n",
    "    \"\"\"\n",
    "    Micro f1 on binary arrays.\n",
    "\n",
    "    Args:\n",
    "        preds (list of lists of ints): Predictions.\n",
    "        truths (list of lists of ints): Ground truths.\n",
    "\n",
    "    Returns:\n",
    "        float: f1 score.\n",
    "    \"\"\"\n",
    "    # Micro : aggregating over all instances\n",
    "    preds = np.concatenate(preds)\n",
    "    truths = np.concatenate(truths)\n",
    "    return f1_score(truths, preds)\n",
    "\n",
    "\n",
    "def spans_to_binary(spans, length=None):\n",
    "    \"\"\"\n",
    "    Converts spans to a binary array indicating whether each character is in the span.\n",
    "\n",
    "    Args:\n",
    "        spans (list of lists of two ints): Spans.\n",
    "\n",
    "    Returns:\n",
    "        np array [length]: Binarized spans.\n",
    "    \"\"\"\n",
    "    length = np.max(spans) if length is None else length\n",
    "    binary = np.zeros(length)\n",
    "    for start, end in spans:\n",
    "        binary[start:end] = 1\n",
    "    return binary\n",
    "\n",
    "\n",
    "def span_micro_f1(preds, truths):\n",
    "    \"\"\"\n",
    "    Micro f1 on spans.\n",
    "\n",
    "    Args:\n",
    "        preds (list of lists of two ints): Prediction spans.\n",
    "        truths (list of lists of two ints): Ground truth spans.\n",
    "\n",
    "    Returns:\n",
    "        float: f1 score.\n",
    "    \"\"\"\n",
    "    bin_preds = []\n",
    "    bin_truths = []\n",
    "    for pred, truth in zip(preds, truths):\n",
    "        if not len(pred) and not len(truth):\n",
    "            continue\n",
    "        length = max(np.max(pred) if len(pred) else 0, np.max(truth) if len(truth) else 0)\n",
    "        bin_preds.append(spans_to_binary(pred, length))\n",
    "        bin_truths.append(spans_to_binary(truth, length))\n",
    "    return micro_f1(bin_preds, bin_truths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labels_for_scoring(df):\n",
    "    # example: ['0 1', '3 4'] -> ['0 1; 3 4']\n",
    "    df['location_for_create_labels'] = [ast.literal_eval(f'[]')] * len(df)\n",
    "    for i in range(len(df)):\n",
    "        lst = df.loc[i, 'location']\n",
    "        if lst:\n",
    "            new_lst = ';'.join(lst)\n",
    "            df.loc[i, 'location_for_create_labels'] = ast.literal_eval(f'[[\"{new_lst}\"]]')\n",
    "    # create labels\n",
    "    truths = []\n",
    "    for location_list in df['location_for_create_labels'].values:\n",
    "        truth = []\n",
    "        if len(location_list) > 0:\n",
    "            location = location_list[0]\n",
    "            for loc in [s.split() for s in location.split(';')]:\n",
    "                start, end = int(loc[0]), int(loc[1])\n",
    "                truth.append([start, end])\n",
    "        truths.append(truth)\n",
    "    return truths\n",
    "\n",
    "\n",
    "def get_char_probs(texts, predictions, tokenizer):\n",
    "    results = [np.zeros(len(t)) for t in texts]\n",
    "    for i, (text, prediction) in enumerate(zip(texts, predictions)):\n",
    "        encoded = tokenizer(text, \n",
    "                            add_special_tokens=True,\n",
    "                            return_offsets_mapping=True)\n",
    "        for idx, (offset_mapping, pred) in enumerate(zip(encoded['offset_mapping'], prediction)):\n",
    "            start = offset_mapping[0]\n",
    "            end = offset_mapping[1]\n",
    "            results[i][start:end] = pred\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_results(char_probs, th=0.5):\n",
    "    results = []\n",
    "    for char_prob in char_probs:\n",
    "        result = np.where(char_prob >= th)[0] + 1\n",
    "        result = [list(g) for _, g in itertools.groupby(result, key=lambda n, c=itertools.count(): n - next(c))]\n",
    "        result = [f\"{min(r)} {max(r)}\" for r in result]\n",
    "        result = \";\".join(result)\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_predictions(results):\n",
    "    predictions = []\n",
    "    for result in results:\n",
    "        prediction = []\n",
    "        if result != \"\":\n",
    "            for loc in [s.split() for s in result.split(';')]:\n",
    "                start, end = int(loc[0]), int(loc[1])\n",
    "                prediction.append([start, end])\n",
    "        predictions.append(prediction)\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Utils\n",
    "# ====================================================\n",
    "def get_score(y_true, y_pred):\n",
    "    score = span_micro_f1(y_true, y_pred)\n",
    "    return score\n",
    "\n",
    "\n",
    "def get_logger(filename=OUTPUT_DIR+'train'):\n",
    "    from logging import INFO, FileHandler, Formatter, StreamHandler, getLogger\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=f\"{filename}.log\")\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = get_logger()\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.cuda.manual_seed(seed) if torch.cuda.is_available() else torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape: (14300, 6)\n",
      "features.shape: (143, 3)\n",
      "patient_notes.shape: (42146, 3)\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Data Loading\n",
    "# ====================================================\n",
    "train = pd.read_csv(root+'/input/nbme-score-clinical-patient-notes/train.csv')\n",
    "train['annotation'] = train['annotation'].apply(ast.literal_eval) # ['mom'] -> [mom]\n",
    "train['location'] = train['location'].apply(ast.literal_eval) # ['0 1'] -> [0, 1]\n",
    "features = pd.read_csv(root+'/input/nbme-score-clinical-patient-notes/features.csv')\n",
    "def preprocess_features(features):\n",
    "    features.loc[27, 'feature_text'] = \"Last-Pap-smear-1-year-ago\"\n",
    "    return features\n",
    "features = preprocess_features(features)\n",
    "patient_notes = pd.read_csv(root+'/input/nbme-score-clinical-patient-notes/patient_notes.csv')\n",
    "\n",
    "print(f\"train.shape: {train.shape}\")\n",
    "#display(train.head())\n",
    "print(f\"features.shape: {features.shape}\")\n",
    "#display(features.head())\n",
    "print(f\"patient_notes.shape: {patient_notes.shape}\")\n",
    "#display(patient_notes.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(features, on=['feature_num', 'case_num'], how='left')\n",
    "train = train.merge(patient_notes, on=['pn_num', 'case_num'], how='left')\n",
    "#display(train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incorrect annotation\n",
    "train.loc[338, 'annotation'] = ast.literal_eval('[[\"father heart attack\"]]')\n",
    "train.loc[338, 'location'] = ast.literal_eval('[[\"764 783\"]]')\n",
    "\n",
    "train.loc[621, 'annotation'] = ast.literal_eval('[[\"for the last 2-3 months\"]]')\n",
    "train.loc[621, 'location'] = ast.literal_eval('[[\"77 100\"]]')\n",
    "\n",
    "train.loc[655, 'annotation'] = ast.literal_eval('[[\"no heat intolerance\"], [\"no cold intolerance\"]]')\n",
    "train.loc[655, 'location'] = ast.literal_eval('[[\"285 292;301 312\"], [\"285 287;296 312\"]]')\n",
    "\n",
    "train.loc[1262, 'annotation'] = ast.literal_eval('[[\"mother thyroid problem\"]]')\n",
    "train.loc[1262, 'location'] = ast.literal_eval('[[\"551 557;565 580\"]]')\n",
    "\n",
    "train.loc[1265, 'annotation'] = ast.literal_eval('[[\\'felt like he was going to \"pass out\"\\']]')\n",
    "train.loc[1265, 'location'] = ast.literal_eval('[[\"131 135;181 212\"]]')\n",
    "\n",
    "train.loc[1396, 'annotation'] = ast.literal_eval('[[\"stool , with no blood\"]]')\n",
    "train.loc[1396, 'location'] = ast.literal_eval('[[\"259 280\"]]')\n",
    "\n",
    "train.loc[1591, 'annotation'] = ast.literal_eval('[[\"diarrhoe non blooody\"]]')\n",
    "train.loc[1591, 'location'] = ast.literal_eval('[[\"176 184;201 212\"]]')\n",
    "\n",
    "train.loc[1615, 'annotation'] = ast.literal_eval('[[\"diarrhea for last 2-3 days\"]]')\n",
    "train.loc[1615, 'location'] = ast.literal_eval('[[\"249 257;271 288\"]]')\n",
    "\n",
    "train.loc[1664, 'annotation'] = ast.literal_eval('[[\"no vaginal discharge\"]]')\n",
    "train.loc[1664, 'location'] = ast.literal_eval('[[\"822 824;907 924\"]]')\n",
    "\n",
    "train.loc[1714, 'annotation'] = ast.literal_eval('[[\"started about 8-10 hours ago\"]]')\n",
    "train.loc[1714, 'location'] = ast.literal_eval('[[\"101 129\"]]')\n",
    "\n",
    "train.loc[1929, 'annotation'] = ast.literal_eval('[[\"no blood in the stool\"]]')\n",
    "train.loc[1929, 'location'] = ast.literal_eval('[[\"531 539;549 561\"]]')\n",
    "\n",
    "train.loc[2134, 'annotation'] = ast.literal_eval('[[\"last sexually active 9 months ago\"]]')\n",
    "train.loc[2134, 'location'] = ast.literal_eval('[[\"540 560;581 593\"]]')\n",
    "\n",
    "train.loc[2191, 'annotation'] = ast.literal_eval('[[\"right lower quadrant pain\"]]')\n",
    "train.loc[2191, 'location'] = ast.literal_eval('[[\"32 57\"]]')\n",
    "\n",
    "train.loc[2553, 'annotation'] = ast.literal_eval('[[\"diarrhoea no blood\"]]')\n",
    "train.loc[2553, 'location'] = ast.literal_eval('[[\"308 317;376 384\"]]')\n",
    "\n",
    "train.loc[3124, 'annotation'] = ast.literal_eval('[[\"sweating\"]]')\n",
    "train.loc[3124, 'location'] = ast.literal_eval('[[\"549 557\"]]')\n",
    "\n",
    "train.loc[3858, 'annotation'] = ast.literal_eval('[[\"previously as regular\"], [\"previously eveyr 28-29 days\"], [\"previously lasting 5 days\"], [\"previously regular flow\"]]')\n",
    "train.loc[3858, 'location'] = ast.literal_eval('[[\"102 123\"], [\"102 112;125 141\"], [\"102 112;143 157\"], [\"102 112;159 171\"]]')\n",
    "\n",
    "train.loc[4373, 'annotation'] = ast.literal_eval('[[\"for 2 months\"]]')\n",
    "train.loc[4373, 'location'] = ast.literal_eval('[[\"33 45\"]]')\n",
    "\n",
    "train.loc[4763, 'annotation'] = ast.literal_eval('[[\"35 year old\"]]')\n",
    "train.loc[4763, 'location'] = ast.literal_eval('[[\"5 16\"]]')\n",
    "\n",
    "train.loc[4782, 'annotation'] = ast.literal_eval('[[\"darker brown stools\"]]')\n",
    "train.loc[4782, 'location'] = ast.literal_eval('[[\"175 194\"]]')\n",
    "\n",
    "train.loc[4908, 'annotation'] = ast.literal_eval('[[\"uncle with peptic ulcer\"]]')\n",
    "train.loc[4908, 'location'] = ast.literal_eval('[[\"700 723\"]]')\n",
    "\n",
    "train.loc[6016, 'annotation'] = ast.literal_eval('[[\"difficulty falling asleep\"]]')\n",
    "train.loc[6016, 'location'] = ast.literal_eval('[[\"225 250\"]]')\n",
    "\n",
    "train.loc[6192, 'annotation'] = ast.literal_eval('[[\"helps to take care of aging mother and in-laws\"]]')\n",
    "train.loc[6192, 'location'] = ast.literal_eval('[[\"197 218;236 260\"]]')\n",
    "\n",
    "train.loc[6380, 'annotation'] = ast.literal_eval('[[\"No hair changes\"], [\"No skin changes\"], [\"No GI changes\"], [\"No palpitations\"], [\"No excessive sweating\"]]')\n",
    "train.loc[6380, 'location'] = ast.literal_eval('[[\"480 482;507 519\"], [\"480 482;499 503;512 519\"], [\"480 482;521 531\"], [\"480 482;533 545\"], [\"480 482;564 582\"]]')\n",
    "\n",
    "train.loc[6562, 'annotation'] = ast.literal_eval('[[\"stressed due to taking care of her mother\"], [\"stressed due to taking care of husbands parents\"]]')\n",
    "train.loc[6562, 'location'] = ast.literal_eval('[[\"290 320;327 337\"], [\"290 320;342 358\"]]')\n",
    "\n",
    "train.loc[6862, 'annotation'] = ast.literal_eval('[[\"stressor taking care of many sick family members\"]]')\n",
    "train.loc[6862, 'location'] = ast.literal_eval('[[\"288 296;324 363\"]]')\n",
    "\n",
    "train.loc[7022, 'annotation'] = ast.literal_eval('[[\"heart started racing and felt numbness for the 1st time in her finger tips\"]]')\n",
    "train.loc[7022, 'location'] = ast.literal_eval('[[\"108 182\"]]')\n",
    "\n",
    "train.loc[7422, 'annotation'] = ast.literal_eval('[[\"first started 5 yrs\"]]')\n",
    "train.loc[7422, 'location'] = ast.literal_eval('[[\"102 121\"]]')\n",
    "\n",
    "train.loc[8876, 'annotation'] = ast.literal_eval('[[\"No shortness of breath\"]]')\n",
    "train.loc[8876, 'location'] = ast.literal_eval('[[\"481 483;533 552\"]]')\n",
    "\n",
    "train.loc[9027, 'annotation'] = ast.literal_eval('[[\"recent URI\"], [\"nasal stuffines, rhinorrhea, for 3-4 days\"]]')\n",
    "train.loc[9027, 'location'] = ast.literal_eval('[[\"92 102\"], [\"123 164\"]]')\n",
    "\n",
    "train.loc[9938, 'annotation'] = ast.literal_eval('[[\"irregularity with her cycles\"], [\"heavier bleeding\"], [\"changes her pad every couple hours\"]]')\n",
    "train.loc[9938, 'location'] = ast.literal_eval('[[\"89 117\"], [\"122 138\"], [\"368 402\"]]')\n",
    "\n",
    "train.loc[9973, 'annotation'] = ast.literal_eval('[[\"gaining 10-15 lbs\"]]')\n",
    "train.loc[9973, 'location'] = ast.literal_eval('[[\"344 361\"]]')\n",
    "\n",
    "train.loc[10513, 'annotation'] = ast.literal_eval('[[\"weight gain\"], [\"gain of 10-16lbs\"]]')\n",
    "train.loc[10513, 'location'] = ast.literal_eval('[[\"600 611\"], [\"607 623\"]]')\n",
    "\n",
    "train.loc[11551, 'annotation'] = ast.literal_eval('[[\"seeing her son knows are not real\"]]')\n",
    "train.loc[11551, 'location'] = ast.literal_eval('[[\"386 400;443 461\"]]')\n",
    "\n",
    "train.loc[11677, 'annotation'] = ast.literal_eval('[[\"saw him once in the kitchen after he died\"]]')\n",
    "train.loc[11677, 'location'] = ast.literal_eval('[[\"160 201\"]]')\n",
    "\n",
    "train.loc[12124, 'annotation'] = ast.literal_eval('[[\"tried Ambien but it didnt work\"]]')\n",
    "train.loc[12124, 'location'] = ast.literal_eval('[[\"325 337;349 366\"]]')\n",
    "\n",
    "train.loc[12279, 'annotation'] = ast.literal_eval('[[\"heard what she described as a party later than evening these things did not actually happen\"]]')\n",
    "train.loc[12279, 'location'] = ast.literal_eval('[[\"405 459;488 524\"]]')\n",
    "\n",
    "train.loc[12289, 'annotation'] = ast.literal_eval('[[\"experienced seeing her son at the kitchen table these things did not actually happen\"]]')\n",
    "train.loc[12289, 'location'] = ast.literal_eval('[[\"353 400;488 524\"]]')\n",
    "\n",
    "train.loc[13238, 'annotation'] = ast.literal_eval('[[\"SCRACHY THROAT\"], [\"RUNNY NOSE\"]]')\n",
    "train.loc[13238, 'location'] = ast.literal_eval('[[\"293 307\"], [\"321 331\"]]')\n",
    "\n",
    "train.loc[13297, 'annotation'] = ast.literal_eval('[[\"without improvement when taking tylenol\"], [\"without improvement when taking ibuprofen\"]]')\n",
    "train.loc[13297, 'location'] = ast.literal_eval('[[\"182 221\"], [\"182 213;225 234\"]]')\n",
    "\n",
    "train.loc[13299, 'annotation'] = ast.literal_eval('[[\"yesterday\"], [\"yesterday\"]]')\n",
    "train.loc[13299, 'location'] = ast.literal_eval('[[\"79 88\"], [\"409 418\"]]')\n",
    "\n",
    "train.loc[13845, 'annotation'] = ast.literal_eval('[[\"headache global\"], [\"headache throughout her head\"]]')\n",
    "train.loc[13845, 'location'] = ast.literal_eval('[[\"86 94;230 236\"], [\"86 94;237 256\"]]')\n",
    "\n",
    "train.loc[14083, 'annotation'] = ast.literal_eval('[[\"headache generalized in her head\"]]')\n",
    "train.loc[14083, 'location'] = ast.literal_eval('[[\"56 64;156 179\"]]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['annotation_length'] = train['annotation'].apply(len)\n",
    "#display(train['annotation_length'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # CV split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# CV split\n",
    "# ====================================================\n",
    "Fold = GroupKFold(n_splits=CFG.n_fold) # for loop for 5 rounds, val_index is a list of index of validation data, others are index of training data\n",
    "groups = train['pn_num'].values # make sure same patient does not appear in train & valid at the same time \n",
    "for n, (train_index, val_index) in enumerate(Fold.split(train, train['location'], groups)): # Fold.split(x, y, groups), each fold has same distribution of y\n",
    "    train.loc[val_index, 'fold'] = int(n) # add fold column, and fill with fold number which this row belongs to evaluation\n",
    "train['fold'] = train['fold'].astype(int) # validation data is len(train)/5 = 2860, each fold 1~5 have 2860 testing data and 11440 training data \n",
    "# display(train.groupby('fold').size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.debug:\n",
    "    # display(train.groupby('fold').size())\n",
    "    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n",
    "    # display(train.groupby('fold').size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# tokenizer\n",
    "# ====================================================\n",
    "tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR+'tokenizer/')\n",
    "CFG.tokenizer = tokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/42146 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42146/42146 [00:55<00:00, 760.35it/s]\n",
      "pn_history max(lengths): 433\n",
      "100%|██████████| 143/143 [00:00<00:00, 3983.04it/s]\n",
      "feature_text max(lengths): 30\n",
      "max_len: 466\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Define max_len\n",
    "# ====================================================\n",
    "for text_col in ['pn_history']:\n",
    "    pn_history_lengths = []\n",
    "    tk0 = tqdm(patient_notes[text_col].fillna(\"\").values, total=len(patient_notes)) # tqdm: progress bar \n",
    "    for text in tk0: # tk0 is a list of text which is text_col column of patient_notes \n",
    "        length = len(tokenizer(text, add_special_tokens=False)['input_ids']) # turn the sentence to index: len([1360, 12, 180, ...])\n",
    "        pn_history_lengths.append(length)\n",
    "    LOGGER.info(f'{text_col} max(lengths): {max(pn_history_lengths)}')\n",
    "\n",
    "for text_col in ['feature_text']:\n",
    "    features_lengths = []\n",
    "    tk0 = tqdm(features[text_col].fillna(\"\").values, total=len(features))\n",
    "    for text in tk0:\n",
    "        length = len(tokenizer(text, add_special_tokens=False)['input_ids']) # 'Intermittent' -> ['In', 'term',...] -> [1360, 12, 180, ...]\n",
    "        features_lengths.append(length)\n",
    "    LOGGER.info(f'{text_col} max(lengths): {max(features_lengths)}')\n",
    "\n",
    "CFG.max_len = max(pn_history_lengths) + max(features_lengths) + 3 # cls 開始 & sep 病例結果 & sep 特徵結尾 \n",
    "LOGGER.info(f\"max_len: {CFG.max_len}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Dataset\n",
    "# ====================================================\n",
    "def prepare_input(cfg, text, feature_text):\n",
    "    inputs = cfg.tokenizer(text, feature_text, \n",
    "                           add_special_tokens=True,\n",
    "                           max_length=CFG.max_len,\n",
    "                           padding=\"max_length\",\n",
    "                           return_offsets_mapping=False)\n",
    "    for k, v in inputs.items(): # k = \n",
    "        inputs[k] = torch.tensor(v, dtype=torch.long)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "def create_label(cfg, text, annotation_length, location_list):\n",
    "    encoded = cfg.tokenizer(text,\n",
    "                            add_special_tokens=True,\n",
    "                            max_length=CFG.max_len,\n",
    "                            padding=\"max_length\",\n",
    "                            return_offsets_mapping=True)\n",
    "    offset_mapping = encoded['offset_mapping'] # index of each token: (0, 0) (0, 1) (1, 2) (2, 3) (3, 4) ...\n",
    "    ignore_idxes = np.where(np.array(encoded.sequence_ids()) != 0)[0] # list all None token index\n",
    "    label = np.zeros(len(offset_mapping))\n",
    "    label[ignore_idxes] = -1 # filled all None token index with = -1; [-1, 0, 0, ..., -1, -1, -1];  0 is no features, -1 is None token  \n",
    "    if annotation_length != 0:\n",
    "        for location in location_list: # location = '237 242;261 268' \n",
    "            for loc in [s.split() for s in location.split(';')]: # [['237', '242'], ['261', '268']] => loc = ['237', '242']\n",
    "                start_idx = -1\n",
    "                end_idx = -1\n",
    "                start, end = int(loc[0]), int(loc[1])\n",
    "                for idx in range(len(offset_mapping)):\n",
    "                    if (start_idx == -1) & (start < offset_mapping[idx][0]): # offset_mapping[idx] = (0, 0); start < 0 -> start_idx = 0 \n",
    "                        start_idx = idx - 1 # find start_ans is in the range of offset_mapping \n",
    "                    if (end_idx == -1) & (end <= offset_mapping[idx][1]): \n",
    "                        end_idx = idx + 1 # label[start_idx:end_idx], the last token is not included, so end_idx + 1 \n",
    "                if start_idx == -1:\n",
    "                    start_idx = end_idx\n",
    "                if (start_idx != -1) & (end_idx != -1):\n",
    "                    label[start_idx:end_idx] = 1 # each is token [-1, 0, 0, ..., 1, 1, ..., -1, -1, -1]; -1 is None token, 0 is no features, 1 is features\n",
    "    return torch.tensor(label, dtype=torch.float)\n",
    "\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.feature_texts = df['feature_text'].values\n",
    "        self.pn_historys = df['pn_history'].values\n",
    "        self.annotation_lengths = df['annotation_length'].values\n",
    "        self.locations = df['location'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.feature_texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        inputs = prepare_input(self.cfg, \n",
    "                               self.pn_historys[item], \n",
    "                               self.feature_texts[item])\n",
    "        label = create_label(self.cfg, \n",
    "                             self.pn_historys[item], \n",
    "                             self.annotation_lengths[item], \n",
    "                             self.locations[item])\n",
    "        return inputs, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Model\n",
    "# ====================================================\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg, config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "\n",
    "        if config_path is None:\n",
    "            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n",
    "        else:\n",
    "            self.config = torch.load(config_path)\n",
    "        if pretrained:\n",
    "            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n",
    "        else:\n",
    "            self.model = AutoModel(self.config)\n",
    "        # only last linear layer is trained\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n",
    "        # TODO: only train this layer\n",
    "        self.fc = nn.Linear(self.config.hidden_size, 1)\n",
    "        self._init_weights(self.fc)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "        \n",
    "    def feature(self, inputs):\n",
    "        outputs = self.model(**inputs)\n",
    "        last_hidden_states = outputs[0]\n",
    "        return last_hidden_states\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        feature = self.feature(inputs)\n",
    "        output = self.fc(self.fc_dropout(feature))\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Helpler functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Helper functions\n",
    "# ====================================================\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    model.train()\n",
    "    if use_scaler:\n",
    "        scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)  \n",
    "    losses = AverageMeter() # calculate the average loss of each batch, \n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "    for step, (inputs, labels) in enumerate(train_loader):\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        if torch.cuda.is_available():\n",
    "            with torch.cuda.amp.autocast(enabled=CFG.apex):\n",
    "                y_preds = model(inputs) # [12, 458, 1]; batch is 12, max_len is 458 \n",
    "        else:\n",
    "            y_preds = model(inputs)\n",
    "        \n",
    "        loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n",
    "        loss = torch.masked_select(loss, labels.view(-1, 1) != -1).mean() # choose the loss of label != -1, and calculate the mean of all none -1 loss\n",
    "        \n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        \n",
    "        losses.update(loss.item(), batch_size) # loss=0.1, batch_size=12, losses.avg = (0.1*12 + 0.2*12 ...)/(12*num_batch)\n",
    "\n",
    "        scaler.scale(loss).backward() if use_scaler else loss.backward()\n",
    "        \n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm) # constrain the gradient to be less than max_grad_norm, to avoid gradient explosion\n",
    "        \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        global_step += 1 # global_step is including the epoch\n",
    "        \n",
    "        if (step + 1) % CFG.gradient_accumulation_steps == 0 and use_scaler:\n",
    "             scaler.step(optimizer)\n",
    "             scaler.update()\n",
    "             optimizer.zero_grad()\n",
    "             global_step += 1\n",
    "        if CFG.batch_scheduler:\n",
    "            scheduler.step()\n",
    "            \n",
    "        end = time.time()\n",
    "        #if step % CFG.print_freq == 0 or step == (len(train_loader)-1) and torch.cuda.is_available():\n",
    "        print('Epoch: [{0}][{1}/{2}] '\n",
    "                'Elapsed {remain:s} '\n",
    "                'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                'Grad: {grad_norm:.4f}  '\n",
    "                'LR: {lr:.8f}  '\n",
    "                .format(epoch+1, step, len(train_loader), \n",
    "                        remain=timeSince(start, float(step+1)/len(train_loader)),\n",
    "                        loss=losses,\n",
    "                        grad_norm=grad_norm,\n",
    "                        lr=scheduler.get_lr()[0]))\n",
    "        if CFG.wandb:\n",
    "            wandb.log({f\"[fold{fold}] loss\": losses.val,\n",
    "                       f\"[fold{fold}] lr\": scheduler.get_lr()[0]})\n",
    "    return losses.avg\n",
    "\n",
    "\n",
    "def valid_fn(valid_loader, model, criterion, device):\n",
    "    losses = AverageMeter()\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    start = end = time.time()\n",
    "    for step, (inputs, labels) in enumerate(valid_loader):\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(inputs)\n",
    "        loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n",
    "        loss = torch.masked_select(loss, labels.view(-1, 1) != -1).mean()\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        preds.append(y_preds.sigmoid().to('cpu').numpy())\n",
    "        end = time.time()\n",
    "        # if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n",
    "        print('EVAL: [{0}/{1}] '\n",
    "                'Elapsed {remain:s} '\n",
    "                'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                .format(step, len(valid_loader),\n",
    "                        loss=losses,\n",
    "                        remain=timeSince(start, float(step+1)/len(valid_loader))))\n",
    "    predictions = np.concatenate(preds)\n",
    "    return losses.avg, predictions\n",
    "\n",
    "\n",
    "def inference_fn(test_loader, model, device):\n",
    "    preds = []\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    tk0 = tqdm(test_loader, total=len(test_loader))\n",
    "    for inputs in tk0:\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(inputs)\n",
    "        preds.append(y_preds.sigmoid().to('cpu').numpy())\n",
    "    predictions = np.concatenate(preds)\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# train loop\n",
    "# ====================================================\n",
    "def train_loop(folds, fold):\n",
    "    \n",
    "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # loader\n",
    "    # ====================================================\n",
    "    train_folds = folds[folds['fold'] != fold].reset_index(drop=True) # if fold = 0, then fold_index = 1, 2, 3, 4 are training data\n",
    "    valid_folds = folds[folds['fold'] == fold].reset_index(drop=True)\n",
    "    valid_texts = valid_folds['pn_history'].values\n",
    "    valid_labels = create_labels_for_scoring(valid_folds)\n",
    "    \n",
    "    train_dataset = TrainDataset(CFG, train_folds)\n",
    "    valid_dataset = TrainDataset(CFG, valid_folds)\n",
    "\n",
    "    # num_workers set to 0 because of an error in this specific torch version for windows\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=CFG.batch_size,\n",
    "                              shuffle=True,\n",
    "                              num_workers=0, pin_memory=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset,\n",
    "                              batch_size=CFG.batch_size,\n",
    "                              shuffle=False,\n",
    "                              num_workers=0, pin_memory=True, drop_last=False)\n",
    "\n",
    "    # ====================================================\n",
    "    # model & optimizer\n",
    "    # ====================================================\n",
    "    model = CustomModel(CFG, config_path=None, pretrained=True)\n",
    "    torch.save(model.config, OUTPUT_DIR+'config.pth')\n",
    "    model.to(device)\n",
    "    # TODO: understand this\n",
    "    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n",
    "        param_optimizer = list(model.named_parameters())\n",
    "        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_parameters = [\n",
    "            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "             'lr': encoder_lr, 'weight_decay': weight_decay},\n",
    "            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "             'lr': encoder_lr, 'weight_decay': 0.0},\n",
    "            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n",
    "             'lr': decoder_lr, 'weight_decay': 0.0}\n",
    "        ]\n",
    "        return optimizer_parameters\n",
    "\n",
    "    optimizer_parameters = get_optimizer_params(model,\n",
    "                                                encoder_lr=CFG.encoder_lr, \n",
    "                                                decoder_lr=CFG.decoder_lr,\n",
    "                                                weight_decay=CFG.weight_decay)\n",
    "    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n",
    "    \n",
    "    # ====================================================\n",
    "    # scheduler\n",
    "    # ====================================================\n",
    "    def get_scheduler(cfg, optimizer, num_train_steps):\n",
    "        if cfg.scheduler=='linear':\n",
    "            scheduler = get_linear_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n",
    "            )\n",
    "        elif cfg.scheduler=='cosine':\n",
    "            scheduler = get_cosine_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n",
    "            )\n",
    "        return scheduler\n",
    "    \n",
    "    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n",
    "    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    criterion = nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "    \n",
    "    best_score = 0.\n",
    "\n",
    "    for epoch in range(CFG.epochs):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # train\n",
    "        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
    "\n",
    "        # eval\n",
    "        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n",
    "        predictions = predictions.reshape((len(valid_folds), CFG.max_len))\n",
    "        \n",
    "        # scoring\n",
    "        char_probs = get_char_probs(valid_texts, predictions, CFG.tokenizer)\n",
    "        results = get_results(char_probs, th=0.5)\n",
    "        preds = get_predictions(results)\n",
    "        score = get_score(valid_labels, preds)\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n",
    "        if CFG.wandb:\n",
    "            wandb.log({f\"[fold{fold}] epoch\": epoch+1, \n",
    "                       f\"[fold{fold}] avg_train_loss\": avg_loss, \n",
    "                       f\"[fold{fold}] avg_val_loss\": avg_val_loss,\n",
    "                       f\"[fold{fold}] score\": score})\n",
    "        \n",
    "        if best_score < score:\n",
    "            best_score = score\n",
    "            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
    "            torch.save({'model': model.state_dict(),\n",
    "                        'predictions': predictions},\n",
    "                        OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n",
    "\n",
    "    predictions = torch.load(OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\", \n",
    "                             map_location=torch.device('cpu'))['predictions']\n",
    "    valid_folds[[i for i in range(CFG.max_len)]] = predictions\n",
    "\n",
    "    torch.cuda.empty_cache() if torch.cuda.is_available() else torch.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return valid_folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n",
      "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaModel: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/953] Elapsed 0m 13s (remain 218m 9s) Loss: 0.8758(0.8758) Grad: 15.0371  LR: 0.00002000  \n",
      "Epoch: [1][1/953] Elapsed 0m 28s (remain 229m 7s) Loss: 0.5323(0.7041) Grad: 10.4361  LR: 0.00002000  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11512\\3529880504.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCFG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_fold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mfold\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mCFG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrn_fold\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m                 \u001b[0m_oof_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m                 \u001b[0moof_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moof_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_oof_df\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                 \u001b[0mLOGGER\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"========== fold: {fold} result ==========\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11512\\3328729416.py\u001b[0m in \u001b[0;36mtrain_loop\u001b[1;34m(folds, fold)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;31m# train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[0mavg_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;31m# eval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11512\\1794449400.py\u001b[0m in \u001b[0;36mtrain_fn\u001b[1;34m(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# loss=0.1, batch_size=12, losses.avg = (0.1*12 + 0.2*12 ...)/(12*num_batch)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m         \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0muse_scaler\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[0mgrad_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCFG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_grad_norm\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# constrain the gradient to be less than max_grad_norm, to avoid gradient explosion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Le\\.conda\\envs\\deberta\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Le\\.conda\\envs\\deberta\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    def get_result(oof_df):\n",
    "        labels = create_labels_for_scoring(oof_df)\n",
    "        predictions = oof_df[[i for i in range(CFG.max_len)]].values\n",
    "        char_probs = get_char_probs(oof_df['pn_history'].values, predictions, CFG.tokenizer)\n",
    "        results = get_results(char_probs, th=0.5)\n",
    "        preds = get_predictions(results)\n",
    "        score = get_score(labels, preds)\n",
    "        LOGGER.info(f'Score: {score:<.4f}')\n",
    "    \n",
    "    if CFG.train:\n",
    "        oof_df = pd.DataFrame()\n",
    "        for fold in range(CFG.n_fold):\n",
    "            if fold in CFG.trn_fold:\n",
    "                _oof_df = train_loop(train, fold)\n",
    "                oof_df = pd.concat([oof_df, _oof_df])\n",
    "                LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "                get_result(_oof_df)\n",
    "        oof_df = oof_df.reset_index(drop=True)\n",
    "        LOGGER.info(f\"========== CV ==========\")\n",
    "        get_result(oof_df)\n",
    "        oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')\n",
    "        \n",
    "    if CFG.wandb:\n",
    "        wandb.finish()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

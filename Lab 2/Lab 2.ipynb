{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x19cdd48f040>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanicDataSet(torch.utils.data.Dataset):\n",
    "  def __init__(self, csv_file: str, train: bool):\n",
    "    original_frame = pd.read_csv(csv_file)\n",
    "    \n",
    "    generator = torch.Generator().manual_seed(42)\n",
    "    train_indices, test_indices = [ds.indices for ds in torch.utils.data.random_split(original_frame, [0.8, 0.2], generator=generator)]\n",
    "    \n",
    "    if train:\n",
    "      data = original_frame.iloc[train_indices]\n",
    "    else:\n",
    "      data = original_frame.iloc[test_indices]\n",
    "\n",
    "    feature_frame = data[[\"Pclass\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Sex\", \"Embarked\"]]\n",
    "\n",
    "    # scale numerical columns\n",
    "    numerical_features = feature_frame.select_dtypes(exclude=object)\n",
    "    categorical_features = feature_frame.select_dtypes(include=object)\n",
    "    scaler = MinMaxScaler((0, 1))\n",
    "    scaler.fit(numerical_features)\n",
    "    numerical_features_arr = scaler.transform(numerical_features)\n",
    "\n",
    "    # one hot encode categorical features\n",
    "    onehot_enc = OneHotEncoder()\n",
    "    onehot_enc.fit(categorical_features)\n",
    "    onehot_features_arr = onehot_enc.transform(categorical_features).toarray()\n",
    "\n",
    "    # concatenate\n",
    "    total_feature_arr = np.concatenate([numerical_features_arr, onehot_features_arr], axis=1)\n",
    "    self.feature_arr = total_feature_arr\n",
    "    self.label_arr = original_frame[\"Survived\"].to_numpy()\n",
    "\n",
    "  def __len__(self):\n",
    "      return len(self.feature_arr)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "      if torch.is_tensor(idx):\n",
    "          idx = idx.tolist()\n",
    "\n",
    "      return (self.feature_arr[idx], self.label_arr[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train = TitanicDataSet('data/titanic.csv', train=True)\n",
    "titanic_val = TitanicDataSet('data/titanic.csv', train=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 11])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset=titanic_train, batch_size=64)\n",
    "features, labels = next(iter(dataloader))\n",
    "features.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UniAILab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

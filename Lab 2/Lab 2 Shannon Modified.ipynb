{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x17cfa5c6e30>"
      ]
     },
     "execution_count": 2215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import MinMaxScaler,OneHotEncoder\n",
    "import torch.optim as optim\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 \n",
    "1. Write a custom dataset class for the titanic data (see the data folder on GitHub).\n",
    "2. Use only the features: \"Pclass\", \"Age\", \"SibSp\", \"Parch\", „Fare“, „Sex“, „Embarked“.\n",
    "3. Preprocess the features accordingly in that class (scaling, one-hot-encoding, etc) and\n",
    "4. split the data into train and validation data (80% and 20%). The constructor of that class\n",
    "should look like this:\n",
    "```\n",
    "titanic_train = TitanicDataSet('titanic.csv', train=True)\n",
    "titanic_val = TitanicDataSet('titanic.csv', train=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TitanicDataSet(root_dir, train):\n",
    "    minmax_scaler = MinMaxScaler()\n",
    "    onehot_enc = OneHotEncoder()\n",
    "\n",
    "    titanic = pd.read_csv(root_dir)\n",
    "\n",
    "    generator = torch.Generator().manual_seed(69)\n",
    "    # trying more test than training data\n",
    "    train_indices, test_indices = [ds.indices for ds in torch.utils.data.random_split(titanic, [0.1, 0.9], generator=generator)]\n",
    "    \n",
    "    if train:\n",
    "      titanic = titanic.iloc[train_indices]\n",
    "    else:\n",
    "      titanic = titanic.iloc[test_indices]\n",
    "\n",
    "    # only need \"Pclass\", \"Age\", \"SibSp\", \"Parch\", „Fare“, „Sex“, „Embarked“\n",
    "    titanic = titanic[[\"Pclass\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Sex\", \"Embarked\", \"Survived\"]]\n",
    "\n",
    "    # because i found NaN in 'Age' column, so filled it with mean value\n",
    "    # remove the NaN data in the dataset, which is from Embarked column, two rows\n",
    "    mean_values = titanic[titanic.select_dtypes(exclude=['object']).columns].mean()\n",
    "    titanic = titanic.fillna(mean_values)\n",
    "    titanic = titanic.dropna()\n",
    "    titanic = titanic.reset_index(drop=True) # reset the index, or combine_features will cause wrong index and length\n",
    "\n",
    "    # devide the data into categorical features and numerical features, and put the 'Survived' column into categorical features\n",
    "    categorical_features = titanic[titanic.select_dtypes(include=['object']).columns.tolist()]\n",
    "    numerical_features = titanic[titanic.select_dtypes(exclude=['object']).columns].drop('Survived', axis=1)\n",
    "    label_features = titanic['Survived']\n",
    "\n",
    "    # use one-hot encoding to transform categorical features to numerical features\n",
    "    numerical_features_arr = minmax_scaler.fit_transform(numerical_features)\n",
    "    categorical_features_arr = onehot_enc.fit_transform(categorical_features).toarray()\n",
    "\n",
    "    # combine the numerical features and categorical features\n",
    "    combined_features = pd.DataFrame(data=numerical_features_arr, columns=numerical_features.columns)\n",
    "    combined_features = pd.concat([combined_features, pd.DataFrame(data=categorical_features_arr)], axis=1)\n",
    "    combined_features = pd.concat([combined_features, label_features], axis=1).reset_index(drop=True)\n",
    "\n",
    "    return combined_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset len: 90\n",
      "val_dataset len: 799\n",
      "total_dataset len: 889\n"
     ]
    }
   ],
   "source": [
    "titanic_train = TitanicDataSet('./data/titanic.csv', train=True)\n",
    "titanic_val = TitanicDataSet('./data/titanic.csv', train=False)\n",
    "print('train_dataset len:', len(titanic_train))\n",
    "print('val_dataset len:', len(titanic_val))\n",
    "print('total_dataset len:', len(titanic_train) + len(titanic_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.331722</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.040051</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.289066</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.008645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.473909</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.031064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.303285</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.004184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.331722</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.048061</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.843594</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.078539</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.031455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.260628</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.014539</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.018911</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.076390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.502346</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.443685</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Pclass       Age  SibSp  Parch      Fare    0    1    2    3    4  \\\n",
       "0      1.0  0.331722   0.00   0.50  0.040051  1.0  0.0  0.0  0.0  1.0   \n",
       "1      1.0  0.289066   0.00   0.00  0.008645  0.0  1.0  0.0  0.0  1.0   \n",
       "2      1.0  0.473909   0.25   0.25  0.031064  0.0  1.0  0.0  0.0  1.0   \n",
       "3      1.0  0.303285   0.00   0.00  0.004184  0.0  1.0  0.0  0.0  1.0   \n",
       "4      0.5  0.331722   0.50   0.75  0.048061  1.0  0.0  0.0  0.0  1.0   \n",
       "..     ...       ...    ...    ...       ...  ...  ...  ...  ...  ...   \n",
       "85     0.0  0.843594   0.00   0.00  0.078539  0.0  1.0  0.0  0.0  1.0   \n",
       "86     0.5  0.000000   0.25   0.25  0.031455  0.0  1.0  0.0  0.0  1.0   \n",
       "87     1.0  0.260628   0.00   0.00  0.014539  0.0  1.0  0.0  0.0  1.0   \n",
       "88     0.5  0.018911   0.25   0.25  0.076390  0.0  1.0  0.0  0.0  1.0   \n",
       "89     0.0  0.502346   0.25   0.50  0.443685  1.0  0.0  0.0  0.0  1.0   \n",
       "\n",
       "    Survived  \n",
       "0          1  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          1  \n",
       "..       ...  \n",
       "85         0  \n",
       "86         1  \n",
       "87         0  \n",
       "88         1  \n",
       "89         1  \n",
       "\n",
       "[90 rows x 11 columns]"
      ]
     },
     "execution_count": 2218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 \n",
    "Build a neural network with: \n",
    "1. [v] one hidden layer of size 3 that predicts the survival of the\n",
    "passengers. \n",
    "2. [v] Use a BCE loss (Hint: you need a sigmoid activation in the output layer).\n",
    "3. [v] Use a data loader to train in batches of size 16 and shuffle the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2219,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data.iloc[idx]\n",
    "        features = torch.FloatTensor(sample[:-1])  # Exclude the 'Survived' column\n",
    "        label = torch.FloatTensor([sample['Survived']])  # 'Survived' column as label\n",
    "        if self.transform:\n",
    "            features = self.transform(features)\n",
    "        return features, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2220,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNet(nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate two nn.Linear modules and assign them as member variables.\n",
    "        \"\"\"\n",
    "        super(TwoLayerNet, self).__init__()\n",
    "        # the weight and bias of linear1 will be initialized \n",
    "        # you can access them by self.linear1.weight and self.linear1.bias\n",
    "        self.linear1 = nn.Linear(D_in, H) # this will create weight, bias for linear1\n",
    "        self.linear2 = nn.Linear(H, D_out) # this will create weight, bias for linear2\n",
    "        self.sigmoid = nn.Sigmoid() # Sigmoid activation for binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Tensor of input data and we must return a Tensor of output data.\n",
    "        We can use Modules defined in the constructor as well as arbitrary operators on Tensors.\n",
    "        \"\"\"\n",
    "        h_relu = F.relu(self.linear1(x))\n",
    "        y_pred = self.sigmoid(self.linear2(h_relu))\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2221,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ManyLayerNet(nn.Module):\n",
    "    def __init__(self, D_in, H, D_out, num_hidden_layers):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate two nn.Linear modules and assign them as member variables.\n",
    "        \"\"\"\n",
    "        super(ManyLayerNet, self).__init__()\n",
    "        # the weight and bias of linear1 will be initialized \n",
    "        # you can access them by self.linear1.weight and self.linear1.bias\n",
    "        # slightly more irregular test results with dropout set to 0.0\n",
    "        self.dropout = nn.Dropout(0.0)\n",
    "        self.first = nn.Linear(D_in, H) # this will create weight, bias for linear1       \n",
    "        # self.hidden_layers = [nn.Linear(H, H) for _ in range(num_hidden_layers)]\n",
    "        self.hidden_layers=[]\n",
    "        self.relu_layers=[]\n",
    "        # alternating Linear and ReLU layers, adding two layers per loop:\n",
    "        for _ in range(int(num_hidden_layers/2)):\n",
    "            self.hidden_layers.append(nn.Linear(H, H))\n",
    "            self.relu_layers.append(nn.Sigmoid())\n",
    "        self.last = nn.Linear(H, D_out)\n",
    "        self.sigmoid = nn.Sigmoid() # Sigmoid activation for binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Tensor of input data and we must return a Tensor of output data.\n",
    "        We can use Modules defined in the constructor as well as arbitrary operators on Tensors.\n",
    "        Dropout is applied before making the prediction in order to ignore some Neurons\n",
    "        \"\"\"\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.first(x))\n",
    "        # can't be applied to ReLU layers which are now part of the hidden layers:\n",
    "        for idx,hidden_layer in enumerate(self.hidden_layers):\n",
    "            if (idx % 5 == 0):\n",
    "                x = self.relu_layers[idx](hidden_layer(x))\n",
    "        y_pred = self.sigmoid(self.last(x))\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N is batch size; \n",
    "# D_in is input dimension; \t10 features from Pclass/Age/SibSp/Parch/Fare/Sex[0\t1]/Embarked[2\t3\t4]\n",
    "# H is hidden dimension (needs to be even number or will round down!); \n",
    "# D_out is output dimension: 1 or 0 (Survived or not) 1 dimension for binary classification\n",
    "\n",
    "\n",
    "\n",
    "# using a single batch increases both training and test accuracies\n",
    "# this might be a case of the network being too confident\n",
    "N, D_in, H, D_out = 32, 10, 12, 1\n",
    "lr = 0.1\n",
    "num_hidden_layers = 20\n",
    "\n",
    "network = ManyLayerNet(D_in, H, D_out, num_hidden_layers)  # H=3 for one hidden layer with 3 neurons\n",
    "optimizer = optim.Adam(network.parameters(), lr)  # RMSProp + Momentum \n",
    "criterion = nn.BCELoss() # Define the loss function as Binary Cross-Entropy Loss\n",
    "\n",
    "n_epochs = 140 # You can adjust the number of epochs as needed\n",
    "log_interval = 16 # Print the training status every log_interval epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2223,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(titanic_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=N, shuffle=True)\n",
    "test_dataset = CustomDataset(titanic_val)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=N, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 2224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features, labels = next(iter(train_dataloader))\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2225,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(epoch):\n",
    "    train_losses = [] # Save the loss value of each training loop (epoch) of the neural network model during the training process\n",
    "    train_accuracies = []\n",
    "    network.train()\n",
    "    correct = 0\n",
    "    cur_count = 0 \n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        # forward propagation\n",
    "        output = network(data)\n",
    "        loss = criterion(output, target)\n",
    "                \n",
    "        # Accuracy\n",
    "        pred = (output >= 0.5).float()  # survival_rate is the threshold\n",
    "        correct += (pred == target).sum().item()\n",
    "        cur_count += len(data)\n",
    "\n",
    "        # backword propagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\t Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "                epoch, \n",
    "                cur_count, \n",
    "                len(train_dataloader.dataset),\n",
    "                100. * cur_count / len(train_dataloader.dataset), \n",
    "                loss.item(), \n",
    "                correct, len(train_dataloader.dataset),\n",
    "                100. * correct / len(train_dataloader.dataset))\n",
    "            )\n",
    "            train_losses.append(loss.item())\n",
    "            \n",
    "            # train_counter.append((batch_idx*16) + ((epoch-1)*len(train_dataloader.dataset)))\n",
    "    return correct / len(train_dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    # test_counter = [i*len(titanic_train) for i in range(n_epochs+1)] # how many data for training so far\n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_dataloader:\n",
    "            # forward propagation\n",
    "            output = network(data)\n",
    "            test_loss += criterion(output, target).item()\n",
    "            # Accuracy\n",
    "            pred = (output >= 0.5).float()  # 0.5 is the threshold\n",
    "            correct += (pred == target).sum().item()\n",
    "    test_loss /= len(test_dataloader.dataset)\n",
    "    test_accuracy = correct / len(test_dataloader.dataset)\n",
    "\n",
    "    return test_accuracy\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, \n",
    "        correct, \n",
    "        len(test_dataloader.dataset),\n",
    "        100. * correct / len(test_dataloader.dataset))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [32/90 (36%)]\tLoss: 0.710369\t Accuracy: 16/90 (18%)\n",
      "Train Epoch: 2 [32/90 (36%)]\tLoss: 0.683641\t Accuracy: 21/90 (23%)\n",
      "Train Epoch: 3 [32/90 (36%)]\tLoss: 0.696106\t Accuracy: 18/90 (20%)\n",
      "Train Epoch: 4 [32/90 (36%)]\tLoss: 0.687548\t Accuracy: 24/90 (27%)\n",
      "Train Epoch: 5 [32/90 (36%)]\tLoss: 0.708755\t Accuracy: 15/90 (17%)\n",
      "Train Epoch: 6 [32/90 (36%)]\tLoss: 0.706172\t Accuracy: 11/90 (12%)\n",
      "Train Epoch: 7 [32/90 (36%)]\tLoss: 0.662532\t Accuracy: 19/90 (21%)\n",
      "Train Epoch: 8 [32/90 (36%)]\tLoss: 0.716143\t Accuracy: 15/90 (17%)\n",
      "Train Epoch: 9 [32/90 (36%)]\tLoss: 0.660158\t Accuracy: 20/90 (22%)\n",
      "Train Epoch: 10 [32/90 (36%)]\tLoss: 0.648690\t Accuracy: 17/90 (19%)\n",
      "Train Epoch: 11 [32/90 (36%)]\tLoss: 0.651930\t Accuracy: 25/90 (28%)\n",
      "Train Epoch: 12 [32/90 (36%)]\tLoss: 0.671612\t Accuracy: 19/90 (21%)\n",
      "Train Epoch: 13 [32/90 (36%)]\tLoss: 0.652299\t Accuracy: 25/90 (28%)\n",
      "Train Epoch: 14 [32/90 (36%)]\tLoss: 0.647150\t Accuracy: 22/90 (24%)\n",
      "Train Epoch: 15 [32/90 (36%)]\tLoss: 0.630539\t Accuracy: 24/90 (27%)\n",
      "Train Epoch: 16 [32/90 (36%)]\tLoss: 0.593501\t Accuracy: 27/90 (30%)\n",
      "Train Epoch: 17 [32/90 (36%)]\tLoss: 0.611417\t Accuracy: 24/90 (27%)\n",
      "Train Epoch: 18 [32/90 (36%)]\tLoss: 0.579493\t Accuracy: 25/90 (28%)\n",
      "Train Epoch: 19 [32/90 (36%)]\tLoss: 0.591795\t Accuracy: 23/90 (26%)\n",
      "Train Epoch: 20 [32/90 (36%)]\tLoss: 0.575145\t Accuracy: 25/90 (28%)\n",
      "Train Epoch: 21 [32/90 (36%)]\tLoss: 0.548865\t Accuracy: 25/90 (28%)\n",
      "Train Epoch: 22 [32/90 (36%)]\tLoss: 0.575464\t Accuracy: 24/90 (27%)\n",
      "Train Epoch: 23 [32/90 (36%)]\tLoss: 0.516865\t Accuracy: 26/90 (29%)\n",
      "Train Epoch: 24 [32/90 (36%)]\tLoss: 0.547518\t Accuracy: 24/90 (27%)\n",
      "Train Epoch: 25 [32/90 (36%)]\tLoss: 0.487729\t Accuracy: 27/90 (30%)\n",
      "Train Epoch: 26 [32/90 (36%)]\tLoss: 0.505086\t Accuracy: 26/90 (29%)\n",
      "Train Epoch: 27 [32/90 (36%)]\tLoss: 0.521417\t Accuracy: 25/90 (28%)\n",
      "Train Epoch: 28 [32/90 (36%)]\tLoss: 0.471751\t Accuracy: 26/90 (29%)\n",
      "Train Epoch: 29 [32/90 (36%)]\tLoss: 0.586950\t Accuracy: 22/90 (24%)\n",
      "Train Epoch: 30 [32/90 (36%)]\tLoss: 0.559734\t Accuracy: 22/90 (24%)\n",
      "Train Epoch: 31 [32/90 (36%)]\tLoss: 0.546560\t Accuracy: 24/90 (27%)\n",
      "Train Epoch: 32 [32/90 (36%)]\tLoss: 0.426310\t Accuracy: 27/90 (30%)\n",
      "Train Epoch: 33 [32/90 (36%)]\tLoss: 0.429056\t Accuracy: 28/90 (31%)\n",
      "Train Epoch: 34 [32/90 (36%)]\tLoss: 0.490979\t Accuracy: 25/90 (28%)\n",
      "Train Epoch: 35 [32/90 (36%)]\tLoss: 0.522872\t Accuracy: 25/90 (28%)\n",
      "Train Epoch: 36 [32/90 (36%)]\tLoss: 0.531033\t Accuracy: 24/90 (27%)\n",
      "Train Epoch: 37 [32/90 (36%)]\tLoss: 0.486818\t Accuracy: 26/90 (29%)\n",
      "Train Epoch: 38 [32/90 (36%)]\tLoss: 0.487773\t Accuracy: 25/90 (28%)\n",
      "Train Epoch: 39 [32/90 (36%)]\tLoss: 0.563693\t Accuracy: 23/90 (26%)\n",
      "Train Epoch: 40 [32/90 (36%)]\tLoss: 0.376642\t Accuracy: 28/90 (31%)\n",
      "Train Epoch: 41 [32/90 (36%)]\tLoss: 0.389813\t Accuracy: 28/90 (31%)\n",
      "Train Epoch: 42 [32/90 (36%)]\tLoss: 0.564994\t Accuracy: 21/90 (23%)\n",
      "Train Epoch: 43 [32/90 (36%)]\tLoss: 0.557105\t Accuracy: 22/90 (24%)\n",
      "Train Epoch: 44 [32/90 (36%)]\tLoss: 0.386013\t Accuracy: 26/90 (29%)\n",
      "Train Epoch: 45 [32/90 (36%)]\tLoss: 0.454857\t Accuracy: 26/90 (29%)\n",
      "Train Epoch: 46 [32/90 (36%)]\tLoss: 0.486965\t Accuracy: 26/90 (29%)\n",
      "Train Epoch: 47 [32/90 (36%)]\tLoss: 0.442999\t Accuracy: 26/90 (29%)\n",
      "Train Epoch: 48 [32/90 (36%)]\tLoss: 0.408343\t Accuracy: 26/90 (29%)\n",
      "Train Epoch: 49 [32/90 (36%)]\tLoss: 0.400267\t Accuracy: 28/90 (31%)\n",
      "Train Epoch: 50 [32/90 (36%)]\tLoss: 0.354163\t Accuracy: 29/90 (32%)\n",
      "Train Epoch: 51 [32/90 (36%)]\tLoss: 0.387525\t Accuracy: 27/90 (30%)\n",
      "Train Epoch: 52 [32/90 (36%)]\tLoss: 0.342770\t Accuracy: 29/90 (32%)\n",
      "Train Epoch: 53 [32/90 (36%)]\tLoss: 0.466576\t Accuracy: 26/90 (29%)\n",
      "Train Epoch: 54 [32/90 (36%)]\tLoss: 0.467995\t Accuracy: 26/90 (29%)\n",
      "Train Epoch: 55 [32/90 (36%)]\tLoss: 0.427746\t Accuracy: 27/90 (30%)\n",
      "Train Epoch: 56 [32/90 (36%)]\tLoss: 0.445018\t Accuracy: 26/90 (29%)\n",
      "Train Epoch: 57 [32/90 (36%)]\tLoss: 0.340066\t Accuracy: 28/90 (31%)\n",
      "Train Epoch: 58 [32/90 (36%)]\tLoss: 0.474532\t Accuracy: 24/90 (27%)\n",
      "Train Epoch: 59 [32/90 (36%)]\tLoss: 0.534010\t Accuracy: 23/90 (26%)\n",
      "Train Epoch: 60 [32/90 (36%)]\tLoss: 0.346491\t Accuracy: 26/90 (29%)\n",
      "Train Epoch: 61 [32/90 (36%)]\tLoss: 0.413910\t Accuracy: 26/90 (29%)\n",
      "Train Epoch: 62 [32/90 (36%)]\tLoss: 0.418041\t Accuracy: 26/90 (29%)\n",
      "Train Epoch: 63 [32/90 (36%)]\tLoss: 0.337251\t Accuracy: 28/90 (31%)\n",
      "Train Epoch: 64 [32/90 (36%)]\tLoss: 0.434793\t Accuracy: 27/90 (30%)\n",
      "Train Epoch: 65 [32/90 (36%)]\tLoss: 0.409090\t Accuracy: 26/90 (29%)\n",
      "Train Epoch: 66 [32/90 (36%)]\tLoss: 0.358038\t Accuracy: 27/90 (30%)\n",
      "Train Epoch: 67 [32/90 (36%)]\tLoss: 0.470838\t Accuracy: 24/90 (27%)\n",
      "Train Epoch: 68 [32/90 (36%)]\tLoss: 0.405012\t Accuracy: 26/90 (29%)\n",
      "Train Epoch: 69 [32/90 (36%)]\tLoss: 0.455740\t Accuracy: 25/90 (28%)\n",
      "Train Epoch: 70 [32/90 (36%)]\tLoss: 0.455850\t Accuracy: 25/90 (28%)\n",
      "Train Epoch: 71 [32/90 (36%)]\tLoss: 0.364143\t Accuracy: 26/90 (29%)\n",
      "Train Epoch: 72 [32/90 (36%)]\tLoss: 0.427626\t Accuracy: 24/90 (27%)\n",
      "Train Epoch: 73 [32/90 (36%)]\tLoss: 0.248897\t Accuracy: 31/90 (34%)\n",
      "Train Epoch: 74 [32/90 (36%)]\tLoss: 0.341985\t Accuracy: 28/90 (31%)\n",
      "Train Epoch: 75 [32/90 (36%)]\tLoss: 0.408674\t Accuracy: 27/90 (30%)\n",
      "Train Epoch: 76 [32/90 (36%)]\tLoss: 0.521186\t Accuracy: 24/90 (27%)\n",
      "Train Epoch: 77 [32/90 (36%)]\tLoss: 0.340998\t Accuracy: 29/90 (32%)\n",
      "Train Epoch: 78 [32/90 (36%)]\tLoss: 0.352573\t Accuracy: 27/90 (30%)\n",
      "Train Epoch: 79 [32/90 (36%)]\tLoss: 0.263449\t Accuracy: 31/90 (34%)\n",
      "Train Epoch: 80 [32/90 (36%)]\tLoss: 0.424496\t Accuracy: 25/90 (28%)\n",
      "Train Epoch: 81 [32/90 (36%)]\tLoss: 0.334366\t Accuracy: 28/90 (31%)\n",
      "Train Epoch: 82 [32/90 (36%)]\tLoss: 0.423388\t Accuracy: 23/90 (26%)\n",
      "Train Epoch: 83 [32/90 (36%)]\tLoss: 0.291212\t Accuracy: 28/90 (31%)\n",
      "Train Epoch: 84 [32/90 (36%)]\tLoss: 0.348104\t Accuracy: 27/90 (30%)\n",
      "Train Epoch: 85 [32/90 (36%)]\tLoss: 0.361375\t Accuracy: 27/90 (30%)\n",
      "Train Epoch: 86 [32/90 (36%)]\tLoss: 0.417506\t Accuracy: 25/90 (28%)\n",
      "Train Epoch: 87 [32/90 (36%)]\tLoss: 0.404291\t Accuracy: 27/90 (30%)\n",
      "Train Epoch: 88 [32/90 (36%)]\tLoss: 0.332983\t Accuracy: 27/90 (30%)\n",
      "Train Epoch: 89 [32/90 (36%)]\tLoss: 0.584295\t Accuracy: 23/90 (26%)\n",
      "Train Epoch: 90 [32/90 (36%)]\tLoss: 0.411769\t Accuracy: 25/90 (28%)\n",
      "Train Epoch: 91 [32/90 (36%)]\tLoss: 0.382160\t Accuracy: 27/90 (30%)\n",
      "Train Epoch: 92 [32/90 (36%)]\tLoss: 0.373119\t Accuracy: 27/90 (30%)\n",
      "Train Epoch: 93 [32/90 (36%)]\tLoss: 0.414140\t Accuracy: 25/90 (28%)\n",
      "Train Epoch: 94 [32/90 (36%)]\tLoss: 0.382136\t Accuracy: 26/90 (29%)\n",
      "Train Epoch: 95 [32/90 (36%)]\tLoss: 0.519525\t Accuracy: 25/90 (28%)\n",
      "Train Epoch: 96 [32/90 (36%)]\tLoss: 0.594051\t Accuracy: 23/90 (26%)\n",
      "Train Epoch: 97 [32/90 (36%)]\tLoss: 0.294770\t Accuracy: 28/90 (31%)\n",
      "Train Epoch: 98 [32/90 (36%)]\tLoss: 0.388551\t Accuracy: 27/90 (30%)\n",
      "Train Epoch: 99 [32/90 (36%)]\tLoss: 0.331392\t Accuracy: 28/90 (31%)\n",
      "Train Epoch: 100 [32/90 (36%)]\tLoss: 0.440166\t Accuracy: 26/90 (29%)\n",
      "Train Epoch: 101 [32/90 (36%)]\tLoss: 0.330225\t Accuracy: 28/90 (31%)\n",
      "Train Epoch: 102 [32/90 (36%)]\tLoss: 0.441745\t Accuracy: 27/90 (30%)\n",
      "Train Epoch: 103 [32/90 (36%)]\tLoss: 0.411875\t Accuracy: 27/90 (30%)\n",
      "Train Epoch: 104 [32/90 (36%)]\tLoss: 0.299446\t Accuracy: 30/90 (33%)\n",
      "Train Epoch: 105 [32/90 (36%)]\tLoss: 0.399119\t Accuracy: 27/90 (30%)\n",
      "Train Epoch: 106 [32/90 (36%)]\tLoss: 0.357657\t Accuracy: 28/90 (31%)\n",
      "Train Epoch: 107 [32/90 (36%)]\tLoss: 0.499758\t Accuracy: 24/90 (27%)\n",
      "Train Epoch: 108 [32/90 (36%)]\tLoss: 0.345143\t Accuracy: 29/90 (32%)\n",
      "Train Epoch: 109 [32/90 (36%)]\tLoss: 0.419549\t Accuracy: 26/90 (29%)\n",
      "Train Epoch: 110 [32/90 (36%)]\tLoss: 0.368181\t Accuracy: 26/90 (29%)\n",
      "Train Epoch: 111 [32/90 (36%)]\tLoss: 0.283907\t Accuracy: 30/90 (33%)\n",
      "Train Epoch: 112 [32/90 (36%)]\tLoss: 0.384022\t Accuracy: 26/90 (29%)\n",
      "Train Epoch: 113 [32/90 (36%)]\tLoss: 0.397252\t Accuracy: 28/90 (31%)\n",
      "Train Epoch: 114 [32/90 (36%)]\tLoss: 0.305787\t Accuracy: 29/90 (32%)\n",
      "Train Epoch: 115 [32/90 (36%)]\tLoss: 0.343886\t Accuracy: 27/90 (30%)\n",
      "Train Epoch: 116 [32/90 (36%)]\tLoss: 0.468445\t Accuracy: 25/90 (28%)\n",
      "Train Epoch: 117 [32/90 (36%)]\tLoss: 0.297799\t Accuracy: 30/90 (33%)\n",
      "Train Epoch: 118 [32/90 (36%)]\tLoss: 0.297281\t Accuracy: 29/90 (32%)\n",
      "Train Epoch: 119 [32/90 (36%)]\tLoss: 0.332137\t Accuracy: 28/90 (31%)\n",
      "Train Epoch: 120 [32/90 (36%)]\tLoss: 0.440878\t Accuracy: 26/90 (29%)\n",
      "Train Epoch: 121 [32/90 (36%)]\tLoss: 0.320208\t Accuracy: 26/90 (29%)\n",
      "Train Epoch: 122 [32/90 (36%)]\tLoss: 0.327070\t Accuracy: 29/90 (32%)\n",
      "Train Epoch: 123 [32/90 (36%)]\tLoss: 0.313308\t Accuracy: 28/90 (31%)\n",
      "Train Epoch: 124 [32/90 (36%)]\tLoss: 0.468103\t Accuracy: 25/90 (28%)\n",
      "Train Epoch: 125 [32/90 (36%)]\tLoss: 0.499870\t Accuracy: 25/90 (28%)\n",
      "Train Epoch: 126 [32/90 (36%)]\tLoss: 0.400281\t Accuracy: 27/90 (30%)\n",
      "Train Epoch: 127 [32/90 (36%)]\tLoss: 0.411724\t Accuracy: 27/90 (30%)\n",
      "Train Epoch: 128 [32/90 (36%)]\tLoss: 0.324452\t Accuracy: 29/90 (32%)\n",
      "Train Epoch: 129 [32/90 (36%)]\tLoss: 0.370746\t Accuracy: 26/90 (29%)\n",
      "Train Epoch: 130 [32/90 (36%)]\tLoss: 0.346154\t Accuracy: 26/90 (29%)\n",
      "Train Epoch: 131 [32/90 (36%)]\tLoss: 0.384604\t Accuracy: 28/90 (31%)\n",
      "Train Epoch: 132 [32/90 (36%)]\tLoss: 0.349278\t Accuracy: 26/90 (29%)\n",
      "Train Epoch: 133 [32/90 (36%)]\tLoss: 0.395332\t Accuracy: 28/90 (31%)\n",
      "Train Epoch: 134 [32/90 (36%)]\tLoss: 0.308441\t Accuracy: 27/90 (30%)\n",
      "Train Epoch: 135 [32/90 (36%)]\tLoss: 0.282323\t Accuracy: 29/90 (32%)\n",
      "Train Epoch: 136 [32/90 (36%)]\tLoss: 0.304910\t Accuracy: 27/90 (30%)\n",
      "Train Epoch: 137 [32/90 (36%)]\tLoss: 0.349188\t Accuracy: 28/90 (31%)\n",
      "Train Epoch: 138 [32/90 (36%)]\tLoss: 0.208905\t Accuracy: 29/90 (32%)\n",
      "Train Epoch: 139 [32/90 (36%)]\tLoss: 0.303486\t Accuracy: 27/90 (30%)\n",
      "Train Epoch: 140 [32/90 (36%)]\tLoss: 0.318221\t Accuracy: 28/90 (31%)\n",
      "Train Epoch: 141 [32/90 (36%)]\tLoss: 0.440566\t Accuracy: 25/90 (28%)\n",
      "Train Epoch: 142 [32/90 (36%)]\tLoss: 0.239478\t Accuracy: 28/90 (31%)\n",
      "Train Epoch: 143 [32/90 (36%)]\tLoss: 0.303940\t Accuracy: 28/90 (31%)\n",
      "Train Epoch: 144 [32/90 (36%)]\tLoss: 0.332812\t Accuracy: 27/90 (30%)\n",
      "Train Epoch: 145 [32/90 (36%)]\tLoss: 0.434498\t Accuracy: 26/90 (29%)\n",
      "Train Epoch: 146 [32/90 (36%)]\tLoss: 0.224617\t Accuracy: 30/90 (33%)\n",
      "Train Epoch: 147 [32/90 (36%)]\tLoss: 0.373744\t Accuracy: 25/90 (28%)\n",
      "Train Epoch: 148 [32/90 (36%)]\tLoss: 0.223952\t Accuracy: 28/90 (31%)\n",
      "Train Epoch: 149 [32/90 (36%)]\tLoss: 0.199813\t Accuracy: 30/90 (33%)\n",
      "Train Epoch: 150 [32/90 (36%)]\tLoss: 0.296074\t Accuracy: 28/90 (31%)\n",
      "Train Epoch: 151 [32/90 (36%)]\tLoss: 0.201586\t Accuracy: 30/90 (33%)\n",
      "Train Epoch: 152 [32/90 (36%)]\tLoss: 0.309431\t Accuracy: 27/90 (30%)\n",
      "Train Epoch: 153 [32/90 (36%)]\tLoss: 0.311571\t Accuracy: 28/90 (31%)\n",
      "Train Epoch: 154 [32/90 (36%)]\tLoss: 0.379743\t Accuracy: 26/90 (29%)\n",
      "Train Epoch: 155 [32/90 (36%)]\tLoss: 0.309497\t Accuracy: 28/90 (31%)\n",
      "Train Epoch: 156 [32/90 (36%)]\tLoss: 0.423668\t Accuracy: 26/90 (29%)\n",
      "Train Epoch: 157 [32/90 (36%)]\tLoss: 0.293004\t Accuracy: 29/90 (32%)\n",
      "Train Epoch: 158 [32/90 (36%)]\tLoss: 0.352469\t Accuracy: 28/90 (31%)\n",
      "Train Epoch: 159 [32/90 (36%)]\tLoss: 0.262770\t Accuracy: 27/90 (30%)\n",
      "Train Epoch: 160 [32/90 (36%)]\tLoss: 0.458161\t Accuracy: 25/90 (28%)\n",
      "Train Epoch: 161 [32/90 (36%)]\tLoss: 0.185294\t Accuracy: 30/90 (33%)\n",
      "Train Epoch: 162 [32/90 (36%)]\tLoss: 0.335442\t Accuracy: 28/90 (31%)\n",
      "Train Epoch: 163 [32/90 (36%)]\tLoss: 0.371843\t Accuracy: 26/90 (29%)\n",
      "Train Epoch: 164 [32/90 (36%)]\tLoss: 0.289472\t Accuracy: 28/90 (31%)\n",
      "Train Epoch: 165 [32/90 (36%)]\tLoss: 0.224165\t Accuracy: 29/90 (32%)\n",
      "Train Epoch: 166 [32/90 (36%)]\tLoss: 0.340912\t Accuracy: 27/90 (30%)\n",
      "Train Epoch: 167 [32/90 (36%)]\tLoss: 0.362071\t Accuracy: 25/90 (28%)\n",
      "Train Epoch: 168 [32/90 (36%)]\tLoss: 0.220720\t Accuracy: 30/90 (33%)\n",
      "Train Epoch: 169 [32/90 (36%)]\tLoss: 0.195591\t Accuracy: 32/90 (36%)\n",
      "Train Epoch: 170 [32/90 (36%)]\tLoss: 0.229126\t Accuracy: 29/90 (32%)\n",
      "Train Epoch: 171 [32/90 (36%)]\tLoss: 0.397525\t Accuracy: 26/90 (29%)\n",
      "Train Epoch: 172 [32/90 (36%)]\tLoss: 0.394202\t Accuracy: 25/90 (28%)\n",
      "Train Epoch: 173 [32/90 (36%)]\tLoss: 0.306465\t Accuracy: 28/90 (31%)\n",
      "Train Epoch: 174 [32/90 (36%)]\tLoss: 0.229461\t Accuracy: 29/90 (32%)\n",
      "Train Epoch: 175 [32/90 (36%)]\tLoss: 0.179451\t Accuracy: 30/90 (33%)\n",
      "Train Epoch: 176 [32/90 (36%)]\tLoss: 0.264542\t Accuracy: 28/90 (31%)\n",
      "Train Epoch: 177 [32/90 (36%)]\tLoss: 0.416198\t Accuracy: 26/90 (29%)\n",
      "Train Epoch: 178 [32/90 (36%)]\tLoss: 0.306247\t Accuracy: 27/90 (30%)\n",
      "Train Epoch: 179 [32/90 (36%)]\tLoss: 0.395100\t Accuracy: 27/90 (30%)\n",
      "Train Epoch: 180 [32/90 (36%)]\tLoss: 0.463148\t Accuracy: 26/90 (29%)\n",
      "Train Epoch: 181 [32/90 (36%)]\tLoss: 0.268665\t Accuracy: 30/90 (33%)\n",
      "Train Epoch: 182 [32/90 (36%)]\tLoss: 0.310541\t Accuracy: 27/90 (30%)\n",
      "Train Epoch: 183 [32/90 (36%)]\tLoss: 0.242958\t Accuracy: 28/90 (31%)\n",
      "Train Epoch: 184 [32/90 (36%)]\tLoss: 0.354120\t Accuracy: 27/90 (30%)\n",
      "Train Epoch: 185 [32/90 (36%)]\tLoss: 0.390025\t Accuracy: 26/90 (29%)\n",
      "Train Epoch: 186 [32/90 (36%)]\tLoss: 0.440634\t Accuracy: 23/90 (26%)\n",
      "Train Epoch: 187 [32/90 (36%)]\tLoss: 0.311821\t Accuracy: 27/90 (30%)\n",
      "Train Epoch: 188 [32/90 (36%)]\tLoss: 0.309960\t Accuracy: 28/90 (31%)\n",
      "Train Epoch: 189 [32/90 (36%)]\tLoss: 0.419833\t Accuracy: 26/90 (29%)\n",
      "Train Epoch: 190 [32/90 (36%)]\tLoss: 0.271735\t Accuracy: 28/90 (31%)\n",
      "Train Epoch: 191 [32/90 (36%)]\tLoss: 0.320376\t Accuracy: 27/90 (30%)\n",
      "Train Epoch: 192 [32/90 (36%)]\tLoss: 0.208219\t Accuracy: 30/90 (33%)\n",
      "Train Epoch: 193 [32/90 (36%)]\tLoss: 0.348460\t Accuracy: 27/90 (30%)\n",
      "Train Epoch: 194 [32/90 (36%)]\tLoss: 0.287443\t Accuracy: 28/90 (31%)\n",
      "Train Epoch: 195 [32/90 (36%)]\tLoss: 0.225254\t Accuracy: 30/90 (33%)\n",
      "Train Epoch: 196 [32/90 (36%)]\tLoss: 0.343937\t Accuracy: 26/90 (29%)\n",
      "Train Epoch: 197 [32/90 (36%)]\tLoss: 0.315043\t Accuracy: 28/90 (31%)\n",
      "Train Epoch: 198 [32/90 (36%)]\tLoss: 0.353720\t Accuracy: 26/90 (29%)\n",
      "Train Epoch: 199 [32/90 (36%)]\tLoss: 0.477872\t Accuracy: 24/90 (27%)\n",
      "Train Epoch: 200 [32/90 (36%)]\tLoss: 0.262514\t Accuracy: 28/90 (31%)\n"
     ]
    }
   ],
   "source": [
    "test()\n",
    "\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train_accuracy = train(epoch)\n",
    "    test_accuracy = test()\n",
    "\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    test_accuracies.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'accuracy')"
      ]
     },
     "execution_count": 2228,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.array(train_accuracies), color='blue', label='Training Accuracy')\n",
    "plt.plot(np.array(test_accuracies), color='red', label='Test Accuracy')\n",
    "# plt.scatter(test_counter, test_losses, color='red')\n",
    "plt.ylim(0, 1)\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "o33BAcW_muVr"
      },
      "outputs": [],
      "source": [
        "# License: BSD\n",
        "# Author: Sasank Chilamkurthy\n",
        "\n",
        "# CNN\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "# others\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "from PIL import Image\n",
        "from tempfile import TemporaryDirectory\n",
        "import time\n",
        "\n",
        "# dataset\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torchvision.datasets import Flowers102\n",
        "\n",
        "# label\n",
        "from scipy.io import loadmat\n",
        "import json\n",
        "import pycocotools\n",
        "\n",
        "cudnn.benchmark = True\n",
        "plt.ion()   # interactive mode\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgd5BL0Am8j3"
      },
      "source": [
        "## Task 1 - Loading Coco Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAdqz8EAnB1M",
        "outputId": "5f2796c9-95d1-41b8-f3f1-f27cb840bf82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "#pw: Letmein42\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "mgFw1UkDnEQF"
      },
      "outputs": [],
      "source": [
        "# from pycocotools.coco import COCO\n",
        "\n",
        "\n",
        "# # instantiate COCO specifying the annotations json path\n",
        "# annotations_path = \"/content/drive/MyDrive/ki-lab-ss23/data/annotations/instances_val2017.json\"\n",
        "\n",
        "# coco = COCO(annotations_path)\n",
        "# # Specify a list of category names of interest\n",
        "# catIds = coco.getCatIds()\n",
        "# # Get the corresponding image ids and images using loadImgs\n",
        "# imgIds = coco.getImgIds()\n",
        "# images = coco.loadImgs(imgIds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "J2j63g0qpnhH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQrunpGKpn49"
      },
      "source": [
        "### Visualizing 1 example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUaM4RA8wi30",
        "outputId": "d8db8c9c-6aa1-449b-d3a5-87b8ac7642cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.93s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        }
      ],
      "source": [
        "from pycocotools.coco import COCO\n",
        "annotations_path = \"/content/drive/MyDrive/ki-lab-ss23/data/annotations/instances_val2017.json\"\n",
        "\n",
        "coco = COCO(annotations_path)\n",
        "imgIds = coco.getImgIds()\n",
        "\n",
        "\n",
        "def load_image(imgIdx):\n",
        "    img_infos = coco.loadImgs(imgIds)\n",
        "    img_path = \"/content/drive/MyDrive/ki-lab-ss23/data/val2017\"\n",
        "\n",
        "    imgInfo = img_infos[imgIdx]\n",
        "\n",
        "    img_path = f\"{img_path}/{imgInfo['file_name']}\"\n",
        "    try:\n",
        "        return Image.open(img_path)\n",
        "    except:\n",
        "        raise Exception()\n",
        "\n",
        "def pil2tensor(pil_image):\n",
        "    return torchvision.transforms.PILToTensor()(pil_image).unsqueeze(0) / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "V5kaY6tPTuZz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ce0b275-198d-49d2-cafb-6ad61a27ce01"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfRV0wckw53A",
        "outputId": "4980bfdc-110f-4a01-870c-63dacb50f2b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2804]\n",
            "[2804, 2911]\n",
            "[2804, 2911, 3175]\n",
            "[2804, 2911, 3175, 2373]\n",
            "[2804, 2911, 3175, 2373, 3412]\n",
            "[2804, 2911, 3175, 2373, 3412, 2325]\n",
            "[2804, 2911, 3175, 2373, 3412, 2325, 2972]\n",
            "[2804, 2911, 3175, 2373, 3412, 2325, 2972, 111]\n",
            "[2804, 2911, 3175, 2373, 3412, 2325, 2972, 111, 17]\n",
            "[2804, 2911, 3175, 2373, 3412, 2325, 2972, 111, 17, 4974]\n",
            "[2804, 2911, 3175, 2373, 3412, 2325, 2972, 111, 17, 4974, 4484]\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "valid_ids = []\n",
        "while True:\n",
        "    i = random.randint(0, len(imgIds))\n",
        "    try:\n",
        "        load_image(i)\n",
        "    except Exception:\n",
        "        continue\n",
        "\n",
        "    valid_ids.append(i)\n",
        "    print(valid_ids)\n",
        "\n",
        "    if len(valid_ids) > 10:\n",
        "        break\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCEfwKg_1G0l",
        "outputId": "6037911e-eb7e-4827-edfd-4eebbe7cfd8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_MobileNet_V3_Large_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_MobileNet_V3_Large_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FasterRCNN(\n",
              "  (transform): GeneralizedRCNNTransform(\n",
              "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
              "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
              "  )\n",
              "  (backbone): BackboneWithFPN(\n",
              "    (body): IntermediateLayerGetter(\n",
              "      (0): Conv2dNormActivation(\n",
              "        (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (1): FrozenBatchNorm2d(16, eps=1e-05)\n",
              "        (2): Hardswish()\n",
              "      )\n",
              "      (1): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
              "            (1): FrozenBatchNorm2d(16, eps=1e-05)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(16, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (2): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(64, eps=1e-05)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
              "            (1): FrozenBatchNorm2d(64, eps=1e-05)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): Conv2dNormActivation(\n",
              "            (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(24, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (3): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(72, eps=1e-05)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
              "            (1): FrozenBatchNorm2d(72, eps=1e-05)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): Conv2dNormActivation(\n",
              "            (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(24, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (4): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(72, eps=1e-05)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
              "            (1): FrozenBatchNorm2d(72, eps=1e-05)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): ReLU()\n",
              "            (scale_activation): Hardsigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(40, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (5): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(120, eps=1e-05)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
              "            (1): FrozenBatchNorm2d(120, eps=1e-05)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): ReLU()\n",
              "            (scale_activation): Hardsigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(40, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (6): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(120, eps=1e-05)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
              "            (1): FrozenBatchNorm2d(120, eps=1e-05)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): ReLU()\n",
              "            (scale_activation): Hardsigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(40, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (7): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(240, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
              "            (1): FrozenBatchNorm2d(240, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (2): Conv2dNormActivation(\n",
              "            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(80, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (8): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(200, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
              "            (1): FrozenBatchNorm2d(200, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (2): Conv2dNormActivation(\n",
              "            (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(80, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (9): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(184, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
              "            (1): FrozenBatchNorm2d(184, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (2): Conv2dNormActivation(\n",
              "            (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(80, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (10): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(184, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
              "            (1): FrozenBatchNorm2d(184, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (2): Conv2dNormActivation(\n",
              "            (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(80, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (11): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(480, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "            (1): FrozenBatchNorm2d(480, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): ReLU()\n",
              "            (scale_activation): Hardsigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(112, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (12): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(672, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
              "            (1): FrozenBatchNorm2d(672, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): ReLU()\n",
              "            (scale_activation): Hardsigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(112, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (13): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(672, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
              "            (1): FrozenBatchNorm2d(672, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): ReLU()\n",
              "            (scale_activation): Hardsigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(160, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (14): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(960, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
              "            (1): FrozenBatchNorm2d(960, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): ReLU()\n",
              "            (scale_activation): Hardsigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(160, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (15): InvertedResidual(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(960, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
              "            (1): FrozenBatchNorm2d(960, eps=1e-05)\n",
              "            (2): Hardswish()\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): ReLU()\n",
              "            (scale_activation): Hardsigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(160, eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (16): Conv2dNormActivation(\n",
              "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): FrozenBatchNorm2d(960, eps=1e-05)\n",
              "        (2): Hardswish()\n",
              "      )\n",
              "    )\n",
              "    (fpn): FeaturePyramidNetwork(\n",
              "      (inner_blocks): ModuleList(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(160, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(960, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (layer_blocks): ModuleList(\n",
              "        (0-1): 2 x Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (extra_blocks): LastLevelMaxPool()\n",
              "    )\n",
              "  )\n",
              "  (rpn): RegionProposalNetwork(\n",
              "    (anchor_generator): AnchorGenerator()\n",
              "    (head): RPNHead(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (cls_logits): Conv2d(256, 15, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bbox_pred): Conv2d(256, 60, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "  )\n",
              "  (roi_heads): RoIHeads(\n",
              "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
              "    (box_head): TwoMLPHead(\n",
              "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
              "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    )\n",
              "    (box_predictor): FastRCNNPredictor(\n",
              "      (cls_score): Linear(in_features=1024, out_features=91, bias=True)\n",
              "      (bbox_pred): Linear(in_features=1024, out_features=364, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# model = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_fpn(pretrained=True)\n",
        "model_res = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=\"FasterRCNN_ResNet50_FPN_Weights.DEFAULT\")\n",
        "model_res.to(device)\n",
        "model_res.eval()\n",
        "\n",
        "model_mobile = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_fpn(weights=torchvision.models.detection.FasterRCNN_MobileNet_V3_Large_FPN_Weights)\n",
        "model_mobile.to(device)\n",
        "model_mobile.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "ZNMMJ2M8y83x",
        "outputId": "23c4e8b6-49b3-43a7-8633-9b4f378b6ca9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2804\n",
            "2911\n",
            "3175\n",
            "2373\n",
            "3412\n",
            "2325\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-39142fa65310>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mimg_as_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil2tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_res\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_as_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mpredictions_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/detection/generalized_rcnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m     99\u001b[0m                     )\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/detection/backbone_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfpn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0mout_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/ops/misc.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrv\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mrm\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 60.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 40.81 MiB is free. Process 6452 has 14.71 GiB memory in use. Of the allocated memory 13.56 GiB is allocated by PyTorch, and 100.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "predictions_res = []\n",
        "predictions_mobile = []\n",
        "for i in valid_ids:\n",
        "    print(i)\n",
        "    img_as_tensor = pil2tensor(load_image(i)).to(device)\n",
        "    prediction = model_res(img_as_tensor)\n",
        "    predictions_res.append(prediction)\n",
        "\n",
        "    prediction = model_mobile(img_as_tensor)\n",
        "    predictions_mobile.append(prediction)\n",
        "    # print(predictions)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmwdOuZp4pJh"
      },
      "source": [
        "# Filter by score > 0.8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUvzd4ok3Gst"
      },
      "outputs": [],
      "source": [
        "# store bounding boxes with score > 0.8 for each prediction\n",
        "valid_boxes_res = []\n",
        "valid_boxes_mobile = []\n",
        "for prediction in predictions_res:\n",
        "    valid_boxes_for_this_prediction = []\n",
        "    for box, label, score in zip(prediction[0][\"boxes\"], prediction[0][\"labels\"], prediction[0][\"scores\"]):\n",
        "        if score < 0.8:\n",
        "            continue\n",
        "\n",
        "        valid_boxes_for_this_prediction.append((box, label, score))\n",
        "    valid_boxes_res.append(valid_boxes_for_this_prediction)\n",
        "\n",
        "\n",
        "for prediction in predictions_mobile:\n",
        "    valid_boxes_for_this_prediction = []\n",
        "    for box, label, score in zip(prediction[0][\"boxes\"], prediction[0][\"labels\"], prediction[0][\"scores\"]):\n",
        "        if score < 0.8:\n",
        "            continue\n",
        "\n",
        "        valid_boxes_for_this_prediction.append((box, label, score))\n",
        "    valid_boxes_mobile.append(valid_boxes_for_this_prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vluWc3Tx4scc"
      },
      "source": [
        "# Visualize results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DpFpXHIe4obY"
      },
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "for id, bboxes_raw_res, bboxes_raw_mobile in zip(valid_ids, valid_boxes_res, valid_boxes_mobile):\n",
        "    pil_image = load_image(id)\n",
        "\n",
        "    imgIds = coco.getImgIds()\n",
        "    img_infos = coco.loadImgs(imgIds)\n",
        "    imgInfo = img_infos[id]\n",
        "    annIds = coco.getAnnIds(imgIds=imgInfo['id'])\n",
        "    anns = coco.loadAnns(annIds)\n",
        "\n",
        "    img_id = img_infos[id][\"id\"]\n",
        "\n",
        "\n",
        "    color = (0, 0, 255)\n",
        "    thickness = 3\n",
        "    # Convert RGB to BGR\n",
        "\n",
        "    open_cv_image = np.array(pil_image)\n",
        "    open_cv_image_pred_res = open_cv_image[:, :, ::-1].copy()\n",
        "    open_cv_image_pred_mobile = open_cv_image[:, :, ::-1].copy()\n",
        "    open_cv_image_truth = open_cv_image[:, :, ::-1].copy()\n",
        "\n",
        "    for ann in anns:\n",
        "        bbox = np.array(ann[\"bbox\"]).astype(\"int\")\n",
        "        label_as_int = ann[\"category_id\"]\n",
        "        label = coco.loadCats(label_as_int)[0][\"name\"]\n",
        "\n",
        "        cv2.rectangle(open_cv_image_truth, (bbox[0], bbox[1]), (bbox[0]+bbox[2], bbox[1]+bbox[3]), color, thickness)\n",
        "\n",
        "        center = (bbox[2] - bbox[0], bbox[3] - bbox[1])\n",
        "        cv2.putText(open_cv_image_truth, label, (bbox[0], bbox[1] - 5), fontFace=0, fontScale=0.8, color=color, thickness=2)\n",
        "\n",
        "\n",
        "    color = (255, 0, 0)\n",
        "    for bbox_raw in bboxes_raw_res:\n",
        "        bbox = bbox_raw[0].cpu().detach().numpy().astype(int)\n",
        "        label_as_int = bbox_raw[1].item()\n",
        "        label = coco.loadCats(label_as_int)[0][\"name\"]\n",
        "\n",
        "        cv2.rectangle(open_cv_image_pred_res, (bbox[0], bbox[1]), (bbox[2], bbox[3]), color, thickness)\n",
        "\n",
        "        center = (bbox[2] - bbox[0], bbox[3] - bbox[1])\n",
        "        cv2.putText(open_cv_image_pred_res, label, (bbox[0], bbox[1] - 5), fontFace=0, fontScale=0.8, color=color, thickness=2)\n",
        "\n",
        "\n",
        "    color = (255, 0, 0)\n",
        "    for bbox_raw in bboxes_raw_mobile:\n",
        "        bbox = bbox_raw[0].cpu().detach().numpy().astype(int)\n",
        "        label_as_int = bbox_raw[1].item()\n",
        "        label = coco.loadCats(label_as_int)[0][\"name\"]\n",
        "\n",
        "        cv2.rectangle(open_cv_image_pred_mobile, (bbox[0], bbox[1]), (bbox[2], bbox[3]), color, thickness)\n",
        "\n",
        "        center = (bbox[2] - bbox[0], bbox[3] - bbox[1])\n",
        "        cv2.putText(open_cv_image_pred_mobile, label, (bbox[0], bbox[1] - 5), fontFace=0, fontScale=0.8, color=color, thickness=2)\n",
        "\n",
        "\n",
        "    combined_image = cv2.hconcat([open_cv_image_pred_res, open_cv_image_truth, open_cv_image_pred_mobile])\n",
        "    cv2_imshow(combined_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0Alfc8bYE7g"
      },
      "source": [
        "## IoU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fix8C1JZNzUi"
      },
      "outputs": [],
      "source": [
        "# call for each image!\n",
        "# some duplicated code because setting valid_id to 5000 would load and print too many images\n",
        "'''predictions_res = []\n",
        "predictions_mobile = []\n",
        "for i in range(5000):\n",
        "    #print(i)\n",
        "    img_as_tensor = pil2tensor(load_image(i)).to(device)\n",
        "    prediction = model_res(img_as_tensor)\n",
        "    predictions_res.append(prediction)\n",
        "\n",
        "    prediction = model_mobile(img_as_tensor)\n",
        "    predictions_mobile.append(prediction)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atdxEMqMa7eu"
      },
      "outputs": [],
      "source": [
        "# store bounding boxes with score > 0.8 for each prediction\n",
        "'''\n",
        "valid_boxes_res = []\n",
        "valid_boxes_mobile = []\n",
        "for prediction in predictions_res:\n",
        "    valid_boxes_for_this_prediction = []\n",
        "    for box, label, score in zip(prediction[0][\"boxes\"], prediction[0][\"labels\"], prediction[0][\"scores\"]):\n",
        "        if score < 0.8:\n",
        "            continue\n",
        "\n",
        "        valid_boxes_for_this_prediction.append((box, label, score))\n",
        "    valid_boxes_res.append(valid_boxes_for_this_prediction)\n",
        "\n",
        "\n",
        "for prediction in predictions_mobile:\n",
        "    valid_boxes_for_this_prediction = []\n",
        "    for box, label, score in zip(prediction[0][\"boxes\"], prediction[0][\"labels\"], prediction[0][\"scores\"]):\n",
        "        if score < 0.8:\n",
        "            continue\n",
        "\n",
        "        valid_boxes_for_this_prediction.append((box, label, score))\n",
        "    valid_boxes_mobile.append(valid_boxes_for_this_prediction)\n",
        "    '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DX1w3TsmXdxh"
      },
      "outputs": [],
      "source": [
        "iou_res = []\n",
        "iou_mobile = []\n",
        "#looping over images\n",
        "for id, bboxes_raw_res, bboxes_raw_mobile in zip(valid_ids, valid_boxes_res, valid_boxes_mobile):\n",
        "    imgIds = coco.getImgIds()\n",
        "    img_infos = coco.loadImgs(imgIds)\n",
        "    imgInfo = img_infos[id]\n",
        "    annIds = coco.getAnnIds(imgIds=imgInfo['id'])\n",
        "    anns = coco.loadAnns(annIds)\n",
        "    img_id = img_infos[id][\"id\"]\n",
        "\n",
        "\n",
        "    # only bboxes_raw_res[i][0] and anns[i][\"bbox\"] are actual bbox\n",
        "    anns = ([[entry[\"bbox\"][0], entry[\"bbox\"][1], entry[\"bbox\"][0]+entry[\"bbox\"][2], entry[\"bbox\"][1]+entry[\"bbox\"][3]] for entry in anns])\n",
        "    bbox_tlist_anns = torch.tensor([entry for entry in anns]).to(device)\n",
        "    bbox_list_res = [entry[0] for entry in bboxes_raw_res]\n",
        "    bbox_tlist_res = torch.stack(bbox_list_res).to(device)\n",
        "    bbox_list_mobile = [entry[0] for entry in bboxes_raw_mobile]\n",
        "    bbox_tlist_mobile = torch.stack(bbox_list_mobile).to(device)\n",
        "    #print(torchvision.ops.box_iou(bbox_tlist_anns, bbox_tlist_anns))\n",
        "    iou_res.append(torchvision.ops.box_iou(bbox_tlist_res, bbox_tlist_anns))\n",
        "    iou_mobile.append(torchvision.ops.box_iou(bbox_tlist_mobile, bbox_tlist_anns))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fzI_yHub_CI"
      },
      "outputs": [],
      "source": [
        "#print(iou_res)\n",
        "print('res iou: ', np.mean([t.cpu().detach().numpy().mean() for t in iou_res]))\n",
        "print('mobile iou: ', np.mean([t.cpu().detach().numpy().mean() for t in iou_mobile]))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
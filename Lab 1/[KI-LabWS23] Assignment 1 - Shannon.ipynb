{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: mps\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7feff0fa1150>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print('device:', device)\n",
    "\n",
    "n_epochs = 50\n",
    "batch_size_train = 64\n",
    "batch_size_test = 100\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 100 # how many batches to wait before logging training status\n",
    "\n",
    "random_seed = 1\n",
    "# cuDNN uses nondeterministic algorithms which can be disabled setting\n",
    "# so we can make sure that the results are reproducible\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 \n",
    "- Load the MNIST dataset into train and test data loaders. \n",
    "- Use the same parameters and apply the same transformations like described in the blog post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./files/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:01<00:00, 8894077.31it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./files/MNIST/raw/train-images-idx3-ubyte.gz to ./files/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./files/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 53505165.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./files/MNIST/raw/train-labels-idx1-ubyte.gz to ./files/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./files/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 20505868.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./files/MNIST/raw/t10k-images-idx3-ubyte.gz to ./files/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./files/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 8750817.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./files/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./files/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Need DataLoaders for the dataset, which is where TorchVision comes in. \n",
    "# We use a batch_size of 64 for training and size 1000 for testing on this dataset. \n",
    "\n",
    "# download the training data \n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./files/', train=True, download=True, # set train to True to download the training data\n",
    "                             transform=torchvision.transforms.Compose([ # define transformations to be applied to the data\n",
    "                               torchvision.transforms.ToTensor(), # convert the data to tensors of PyTorch \n",
    "                               torchvision.transforms.Normalize( # normalize the data\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train,  # setup the batch size\n",
    "  shuffle=True) # randomly shuffle the data, increases the randomness of the data\n",
    "\n",
    "# download the test data\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./files/', train=False, download=True, # set train to False to download the test data\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, \n",
    "  shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 \n",
    "- Create a feedforward neural network with same structure as in 0_Simple_NN.py \n",
    "  -  an input layer, \n",
    "  -  one hidden layer with 100 neurons \n",
    "  -  and an output layer\n",
    "-  You need to change the following:\n",
    "   -  Adjust the size of the input layer to the size of the MNIST images (28x28)\n",
    "   -  Use log_softmax as activation function for the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNet(nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate two nn.Linear modules and assign them as member variables.\n",
    "        \"\"\"\n",
    "        super(TwoLayerNet, self).__init__()\n",
    "        # the weight and bias of linear1 will be initialized \n",
    "        # you can access them by self.linear1.weight and self.linear1.bias\n",
    "        self.linear1 = nn.Linear(D_in, H, device) # this will create weight, bias for linear1\n",
    "        self.linear2 = nn.Linear(H, D_out, device) # this will create weight, bias for linear2\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Tensor of input data and we must return a Tensor of output data.\n",
    "        We can use Modules defined in the constructor as well as arbitrary operators on Tensors.\n",
    "        \"\"\"\n",
    "        x.to(device) # move the data to the device (cpu or gpu)\n",
    "        h_relu = F.relu(self.linear1(x))\n",
    "        y_pred = F.log_softmax(self.linear2(h_relu), dim=1)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N is batch size; \n",
    "# D_in is input dimension, which is 28*28, because the image is 28*28 pixels;\n",
    "# H is hidden dimension (Only one hidden layer, but containing 100 neurons.); \n",
    "# D_out is output dimension\n",
    "\n",
    "# Now let's initialize the network and the optimizer.\n",
    "network = TwoLayerNet(D_in = 784, H=100, D_out=10)\n",
    "optimizer = optim.SGD(network.parameters(), \n",
    "                      lr=learning_rate,\n",
    "                      momentum=momentum)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3 \n",
    "- Train your network on the training data for 50 epochs using the negative log likelihood loss (F.nll_loss)\n",
    "- Create a plot of training loss (but without the test loss). \n",
    "  \n",
    "# Task 4\n",
    "- Test the network on the MNIST test data and give out accuracy and loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = [] # Save the loss value of each training loop (epoch) of the neural network model during the training process\n",
    "train_counter = [] # Save the number of images for training so far\n",
    "test_losses = [] # Save the loss value of each test loop (epoch) of the neural network model during the training process\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs)] # how many images for training so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    network.train() # set the network to training mode\n",
    "    correct = 0 # the number of correct predictions\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # batch_idx:will get 0, 1, 2, 3... in order, used to indicate which batch of the dataset is currently being processed\n",
    "        # data: the images in the current batch, target: the labels of the images in the current batch\n",
    "        # (data, tartget) is a tuple, which convenience to process the data and target at the same time\n",
    "        optimizer.zero_grad()\n",
    "        data = data.view(data.size(0), -1) # reshape the data to be a vector of 784 elements (28*28)\n",
    "\n",
    "        # move the data to the device (cpu or gpu)\n",
    "        data.to(device)\n",
    "        target.to(device)\n",
    "\n",
    "        # forward propagation\n",
    "        output = network(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "\n",
    "        # calculate the number of correct predictions\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "\n",
    "        # backward propagation\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "\n",
    "        # in order to not print out every single batch, we use log_interval to print out the loss value every log_interval batches\n",
    "        if batch_idx % log_interval == 0: # print when batch_idx is 640, 1280, 1920 ...\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "                epoch, \n",
    "                batch_idx * len(data), \n",
    "                len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), \n",
    "                loss.item(),\n",
    "                correct, len(train_loader.dataset), # correct is the number of correct predictions\n",
    "                100. * correct / len(train_loader.dataset)\n",
    "                )) # loss.item() is the loss value of the current batch\n",
    "            \n",
    "            train_losses.append(loss.item())\n",
    "            train_counter.append(\n",
    "                (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "            \n",
    "            # Save the model and optimizer parameters (their internal state), so we can continue training from previously saved state if needed.\n",
    "            # We'd just need to call .load_state_dict(torch.load(PATH)) to load the state.\n",
    "            torch.save(network.state_dict(), './results/model.pth') # save the model\n",
    "            torch.save(optimizer.state_dict(), './results/optimizer.pth') # save the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    network.eval() # set the network to evaluation mode\n",
    "    test_loss = 0 # the loss value of the current test loop (epoch)\n",
    "    correct = 0 # the number of correct predictions\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader: # loop over the test data\n",
    "            data = data.view(-1, 784) # reshape the data to be a vector of 784 elements (28*28)\n",
    "            output = network(data) # put the data into the network to get the output\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            # output is a tensor of shape (batch_size, 10), which contains the log-probability of each class\n",
    "            # we use .data.max(1m keepdim=True)[1] to get the index of the max log-probability, [1] means the index of the max log-probability rather than the max log-probability itself\n",
    "            pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            # pred is a tensor of shape (batch_size, 1), which contains the index of the max log-probability\n",
    "            # target is a tensor of shape (batch_size), which contains the ground truth label of the image\n",
    "            # pred.eq(target.data.view_as(pred)) return a boolean tensor, and we use .sum() to get the number of correct predictions 'True' in the boolean tensor\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    test_loss /= len(test_loader.dataset) # get the average loss value of the current test loop (epoch)\n",
    "    test_losses.append(test_loss) # save the loss value of the current test loop (epoch)\n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset), # correct is the number of correct predictions\n",
    "        100. * correct / len(test_loader.dataset))) # calculate the accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: mps\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.395514, Accuracy: 8/60000 (0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.600250, Accuracy: 4461/60000 (7%)\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.436474, Accuracy: 9983/60000 (17%)\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.481911, Accuracy: 15703/60000 (26%)\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.380317, Accuracy: 21418/60000 (36%)\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.129691, Accuracy: 27188/60000 (45%)\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.223789, Accuracy: 33012/60000 (55%)\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.351787, Accuracy: 38829/60000 (65%)\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.279547, Accuracy: 44658/60000 (74%)\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.538881, Accuracy: 50556/60000 (84%)\n",
      "\n",
      "Test set: Avg. loss: 0.2673, Accuracy: 9247/10000 (92%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.284558, Accuracy: 59/60000 (0%)\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.249058, Accuracy: 5924/60000 (10%)\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.209405, Accuracy: 11865/60000 (20%)\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.409481, Accuracy: 17778/60000 (30%)\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.296153, Accuracy: 23736/60000 (40%)\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.236771, Accuracy: 29689/60000 (49%)\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.229103, Accuracy: 35674/60000 (59%)\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.419751, Accuracy: 41641/60000 (69%)\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.091249, Accuracy: 47660/60000 (79%)\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.141819, Accuracy: 53652/60000 (89%)\n",
      "\n",
      "Test set: Avg. loss: 0.2100, Accuracy: 9384/10000 (94%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.293956, Accuracy: 59/60000 (0%)\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.350497, Accuracy: 6108/60000 (10%)\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.180049, Accuracy: 12124/60000 (20%)\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.092172, Accuracy: 18158/60000 (30%)\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.284877, Accuracy: 24199/60000 (40%)\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.337053, Accuracy: 30252/60000 (50%)\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.141322, Accuracy: 36285/60000 (60%)\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.142789, Accuracy: 42309/60000 (71%)\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.117576, Accuracy: 48344/60000 (81%)\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.104511, Accuracy: 54436/60000 (91%)\n",
      "\n",
      "Test set: Avg. loss: 0.1744, Accuracy: 9498/10000 (95%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.279994, Accuracy: 58/60000 (0%)\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.216224, Accuracy: 6135/60000 (10%)\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.102988, Accuracy: 12203/60000 (20%)\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.151726, Accuracy: 18308/60000 (31%)\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.091218, Accuracy: 24391/60000 (41%)\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.086683, Accuracy: 30509/60000 (51%)\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.156707, Accuracy: 36598/60000 (61%)\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.188386, Accuracy: 42716/60000 (71%)\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.144712, Accuracy: 48837/60000 (81%)\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.037875, Accuracy: 54958/60000 (92%)\n",
      "\n",
      "Test set: Avg. loss: 0.1550, Accuracy: 9539/10000 (95%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.079037, Accuracy: 62/60000 (0%)\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.082463, Accuracy: 6187/60000 (10%)\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.072972, Accuracy: 12348/60000 (21%)\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.159505, Accuracy: 18479/60000 (31%)\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.224295, Accuracy: 24615/60000 (41%)\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.109748, Accuracy: 30777/60000 (51%)\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.191232, Accuracy: 36926/60000 (62%)\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.120866, Accuracy: 43088/60000 (72%)\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.096277, Accuracy: 49244/60000 (82%)\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.104546, Accuracy: 55367/60000 (92%)\n",
      "\n",
      "Test set: Avg. loss: 0.1369, Accuracy: 9595/10000 (96%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.125752, Accuracy: 63/60000 (0%)\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.143809, Accuracy: 6246/60000 (10%)\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.055840, Accuracy: 12409/60000 (21%)\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.075253, Accuracy: 18573/60000 (31%)\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.234696, Accuracy: 24754/60000 (41%)\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.195163, Accuracy: 30962/60000 (52%)\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.118562, Accuracy: 37122/60000 (62%)\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.091355, Accuracy: 43290/60000 (72%)\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.206478, Accuracy: 49478/60000 (82%)\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.032173, Accuracy: 55655/60000 (93%)\n",
      "\n",
      "Test set: Avg. loss: 0.1211, Accuracy: 9635/10000 (96%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.065586, Accuracy: 63/60000 (0%)\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.049511, Accuracy: 6241/60000 (10%)\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.095334, Accuracy: 12440/60000 (21%)\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.160701, Accuracy: 18628/60000 (31%)\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.076675, Accuracy: 24848/60000 (41%)\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.075360, Accuracy: 31042/60000 (52%)\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.057329, Accuracy: 37257/60000 (62%)\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.044047, Accuracy: 43456/60000 (72%)\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.177879, Accuracy: 49659/60000 (83%)\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.137702, Accuracy: 55858/60000 (93%)\n",
      "\n",
      "Test set: Avg. loss: 0.1148, Accuracy: 9642/10000 (96%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.153123, Accuracy: 61/60000 (0%)\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.097953, Accuracy: 6297/60000 (10%)\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.119146, Accuracy: 12525/60000 (21%)\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.046589, Accuracy: 18741/60000 (31%)\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.101599, Accuracy: 24970/60000 (42%)\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.077884, Accuracy: 31187/60000 (52%)\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.025042, Accuracy: 37397/60000 (62%)\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.061617, Accuracy: 43603/60000 (73%)\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.051958, Accuracy: 49819/60000 (83%)\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.094027, Accuracy: 56043/60000 (93%)\n",
      "\n",
      "Test set: Avg. loss: 0.1049, Accuracy: 9682/10000 (97%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.195897, Accuracy: 60/60000 (0%)\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.090567, Accuracy: 6293/60000 (10%)\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.083984, Accuracy: 12518/60000 (21%)\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.055836, Accuracy: 18766/60000 (31%)\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.085434, Accuracy: 25000/60000 (42%)\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.116502, Accuracy: 31219/60000 (52%)\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.194070, Accuracy: 37453/60000 (62%)\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.059894, Accuracy: 43686/60000 (73%)\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.091950, Accuracy: 49925/60000 (83%)\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.147457, Accuracy: 56154/60000 (94%)\n",
      "\n",
      "Test set: Avg. loss: 0.1004, Accuracy: 9705/10000 (97%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.034867, Accuracy: 63/60000 (0%)\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.049396, Accuracy: 6319/60000 (11%)\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.069824, Accuracy: 12552/60000 (21%)\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.109961, Accuracy: 18798/60000 (31%)\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.097779, Accuracy: 25058/60000 (42%)\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.138551, Accuracy: 31318/60000 (52%)\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.056909, Accuracy: 37552/60000 (63%)\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.068156, Accuracy: 43800/60000 (73%)\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.064259, Accuracy: 50060/60000 (83%)\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.147444, Accuracy: 56309/60000 (94%)\n",
      "\n",
      "Test set: Avg. loss: 0.0965, Accuracy: 9708/10000 (97%)\n",
      "\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.041634, Accuracy: 64/60000 (0%)\n",
      "Train Epoch: 11 [6400/60000 (11%)]\tLoss: 0.023137, Accuracy: 6306/60000 (11%)\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.054539, Accuracy: 12572/60000 (21%)\n",
      "Train Epoch: 11 [19200/60000 (32%)]\tLoss: 0.064029, Accuracy: 18837/60000 (31%)\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.053127, Accuracy: 25083/60000 (42%)\n",
      "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 0.097992, Accuracy: 31365/60000 (52%)\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.056431, Accuracy: 37627/60000 (63%)\n",
      "Train Epoch: 11 [44800/60000 (75%)]\tLoss: 0.114943, Accuracy: 43890/60000 (73%)\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.030050, Accuracy: 50154/60000 (84%)\n",
      "Train Epoch: 11 [57600/60000 (96%)]\tLoss: 0.191965, Accuracy: 56409/60000 (94%)\n",
      "\n",
      "Test set: Avg. loss: 0.0940, Accuracy: 9705/10000 (97%)\n",
      "\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.023124, Accuracy: 64/60000 (0%)\n",
      "Train Epoch: 12 [6400/60000 (11%)]\tLoss: 0.058577, Accuracy: 6331/60000 (11%)\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.094052, Accuracy: 12611/60000 (21%)\n",
      "Train Epoch: 12 [19200/60000 (32%)]\tLoss: 0.072275, Accuracy: 18899/60000 (31%)\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.059245, Accuracy: 25183/60000 (42%)\n",
      "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 0.126724, Accuracy: 31459/60000 (52%)\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.099410, Accuracy: 37718/60000 (63%)\n",
      "Train Epoch: 12 [44800/60000 (75%)]\tLoss: 0.077135, Accuracy: 43974/60000 (73%)\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.075924, Accuracy: 50257/60000 (84%)\n",
      "Train Epoch: 12 [57600/60000 (96%)]\tLoss: 0.019104, Accuracy: 56533/60000 (94%)\n",
      "\n",
      "Test set: Avg. loss: 0.0905, Accuracy: 9728/10000 (97%)\n",
      "\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.049792, Accuracy: 62/60000 (0%)\n",
      "Train Epoch: 13 [6400/60000 (11%)]\tLoss: 0.067246, Accuracy: 6365/60000 (11%)\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.088398, Accuracy: 12649/60000 (21%)\n",
      "Train Epoch: 13 [19200/60000 (32%)]\tLoss: 0.060649, Accuracy: 18931/60000 (32%)\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.141472, Accuracy: 25218/60000 (42%)\n",
      "Train Epoch: 13 [32000/60000 (53%)]\tLoss: 0.036170, Accuracy: 31491/60000 (52%)\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.083682, Accuracy: 37757/60000 (63%)\n",
      "Train Epoch: 13 [44800/60000 (75%)]\tLoss: 0.017243, Accuracy: 44051/60000 (73%)\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.135777, Accuracy: 50332/60000 (84%)\n",
      "Train Epoch: 13 [57600/60000 (96%)]\tLoss: 0.029303, Accuracy: 56630/60000 (94%)\n",
      "\n",
      "Test set: Avg. loss: 0.0856, Accuracy: 9737/10000 (97%)\n",
      "\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.073104, Accuracy: 63/60000 (0%)\n",
      "Train Epoch: 14 [6400/60000 (11%)]\tLoss: 0.035550, Accuracy: 6343/60000 (11%)\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.036736, Accuracy: 12637/60000 (21%)\n",
      "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 0.042785, Accuracy: 18918/60000 (32%)\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.040637, Accuracy: 25234/60000 (42%)\n",
      "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.022626, Accuracy: 31523/60000 (53%)\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.096777, Accuracy: 37828/60000 (63%)\n",
      "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 0.080180, Accuracy: 44109/60000 (74%)\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.074069, Accuracy: 50392/60000 (84%)\n",
      "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 0.102363, Accuracy: 56679/60000 (94%)\n",
      "\n",
      "Test set: Avg. loss: 0.0814, Accuracy: 9748/10000 (97%)\n",
      "\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.042051, Accuracy: 62/60000 (0%)\n",
      "Train Epoch: 15 [6400/60000 (11%)]\tLoss: 0.063562, Accuracy: 6364/60000 (11%)\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.091721, Accuracy: 12683/60000 (21%)\n",
      "Train Epoch: 15 [19200/60000 (32%)]\tLoss: 0.088585, Accuracy: 18991/60000 (32%)\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.078346, Accuracy: 25298/60000 (42%)\n",
      "Train Epoch: 15 [32000/60000 (53%)]\tLoss: 0.071363, Accuracy: 31593/60000 (53%)\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.015037, Accuracy: 37901/60000 (63%)\n",
      "Train Epoch: 15 [44800/60000 (75%)]\tLoss: 0.058132, Accuracy: 44190/60000 (74%)\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.060733, Accuracy: 50485/60000 (84%)\n",
      "Train Epoch: 15 [57600/60000 (96%)]\tLoss: 0.053442, Accuracy: 56770/60000 (95%)\n",
      "\n",
      "Test set: Avg. loss: 0.0821, Accuracy: 9752/10000 (98%)\n",
      "\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.022941, Accuracy: 64/60000 (0%)\n",
      "Train Epoch: 16 [6400/60000 (11%)]\tLoss: 0.051636, Accuracy: 6372/60000 (11%)\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 0.066532, Accuracy: 12684/60000 (21%)\n",
      "Train Epoch: 16 [19200/60000 (32%)]\tLoss: 0.030741, Accuracy: 18981/60000 (32%)\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 0.027237, Accuracy: 25289/60000 (42%)\n",
      "Train Epoch: 16 [32000/60000 (53%)]\tLoss: 0.042150, Accuracy: 31591/60000 (53%)\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 0.041146, Accuracy: 37888/60000 (63%)\n",
      "Train Epoch: 16 [44800/60000 (75%)]\tLoss: 0.061772, Accuracy: 44187/60000 (74%)\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.043535, Accuracy: 50484/60000 (84%)\n",
      "Train Epoch: 16 [57600/60000 (96%)]\tLoss: 0.114855, Accuracy: 56786/60000 (95%)\n",
      "\n",
      "Test set: Avg. loss: 0.0823, Accuracy: 9737/10000 (97%)\n",
      "\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.056722, Accuracy: 62/60000 (0%)\n",
      "Train Epoch: 17 [6400/60000 (11%)]\tLoss: 0.027879, Accuracy: 6373/60000 (11%)\n",
      "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 0.033810, Accuracy: 12692/60000 (21%)\n",
      "Train Epoch: 17 [19200/60000 (32%)]\tLoss: 0.025658, Accuracy: 19010/60000 (32%)\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 0.100808, Accuracy: 25321/60000 (42%)\n",
      "Train Epoch: 17 [32000/60000 (53%)]\tLoss: 0.014347, Accuracy: 31640/60000 (53%)\n",
      "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 0.035790, Accuracy: 37958/60000 (63%)\n",
      "Train Epoch: 17 [44800/60000 (75%)]\tLoss: 0.025071, Accuracy: 44276/60000 (74%)\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 0.029510, Accuracy: 50574/60000 (84%)\n",
      "Train Epoch: 17 [57600/60000 (96%)]\tLoss: 0.053982, Accuracy: 56880/60000 (95%)\n",
      "\n",
      "Test set: Avg. loss: 0.0790, Accuracy: 9756/10000 (98%)\n",
      "\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.064115, Accuracy: 63/60000 (0%)\n",
      "Train Epoch: 18 [6400/60000 (11%)]\tLoss: 0.067160, Accuracy: 6386/60000 (11%)\n",
      "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 0.045750, Accuracy: 12709/60000 (21%)\n",
      "Train Epoch: 18 [19200/60000 (32%)]\tLoss: 0.092732, Accuracy: 19033/60000 (32%)\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 0.022980, Accuracy: 25361/60000 (42%)\n",
      "Train Epoch: 18 [32000/60000 (53%)]\tLoss: 0.036166, Accuracy: 31671/60000 (53%)\n",
      "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 0.074979, Accuracy: 37988/60000 (63%)\n",
      "Train Epoch: 18 [44800/60000 (75%)]\tLoss: 0.036360, Accuracy: 44292/60000 (74%)\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 0.061268, Accuracy: 50612/60000 (84%)\n",
      "Train Epoch: 18 [57600/60000 (96%)]\tLoss: 0.025155, Accuracy: 56924/60000 (95%)\n",
      "\n",
      "Test set: Avg. loss: 0.0765, Accuracy: 9765/10000 (98%)\n",
      "\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.069315, Accuracy: 63/60000 (0%)\n",
      "Train Epoch: 19 [6400/60000 (11%)]\tLoss: 0.068602, Accuracy: 6394/60000 (11%)\n",
      "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 0.075144, Accuracy: 12718/60000 (21%)\n",
      "Train Epoch: 19 [19200/60000 (32%)]\tLoss: 0.030756, Accuracy: 19047/60000 (32%)\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 0.025854, Accuracy: 25365/60000 (42%)\n",
      "Train Epoch: 19 [32000/60000 (53%)]\tLoss: 0.065998, Accuracy: 31700/60000 (53%)\n",
      "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 0.067290, Accuracy: 38028/60000 (63%)\n",
      "Train Epoch: 19 [44800/60000 (75%)]\tLoss: 0.107917, Accuracy: 44352/60000 (74%)\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 0.023628, Accuracy: 50659/60000 (84%)\n",
      "Train Epoch: 19 [57600/60000 (96%)]\tLoss: 0.017896, Accuracy: 56989/60000 (95%)\n",
      "\n",
      "Test set: Avg. loss: 0.0776, Accuracy: 9760/10000 (98%)\n",
      "\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.094086, Accuracy: 61/60000 (0%)\n",
      "Train Epoch: 20 [6400/60000 (11%)]\tLoss: 0.015224, Accuracy: 6389/60000 (11%)\n",
      "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 0.045947, Accuracy: 12736/60000 (21%)\n",
      "Train Epoch: 20 [19200/60000 (32%)]\tLoss: 0.022616, Accuracy: 19069/60000 (32%)\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 0.021095, Accuracy: 25402/60000 (42%)\n",
      "Train Epoch: 20 [32000/60000 (53%)]\tLoss: 0.052656, Accuracy: 31731/60000 (53%)\n",
      "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 0.109736, Accuracy: 38058/60000 (63%)\n",
      "Train Epoch: 20 [44800/60000 (75%)]\tLoss: 0.017075, Accuracy: 44385/60000 (74%)\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 0.076121, Accuracy: 50708/60000 (85%)\n",
      "Train Epoch: 20 [57600/60000 (96%)]\tLoss: 0.015160, Accuracy: 57029/60000 (95%)\n",
      "\n",
      "Test set: Avg. loss: 0.0751, Accuracy: 9772/10000 (98%)\n",
      "\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 0.020665, Accuracy: 64/60000 (0%)\n",
      "Train Epoch: 21 [6400/60000 (11%)]\tLoss: 0.029481, Accuracy: 6389/60000 (11%)\n",
      "Train Epoch: 21 [12800/60000 (21%)]\tLoss: 0.007665, Accuracy: 12748/60000 (21%)\n",
      "Train Epoch: 21 [19200/60000 (32%)]\tLoss: 0.008600, Accuracy: 19082/60000 (32%)\n",
      "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 0.044442, Accuracy: 25418/60000 (42%)\n",
      "Train Epoch: 21 [32000/60000 (53%)]\tLoss: 0.009600, Accuracy: 31746/60000 (53%)\n",
      "Train Epoch: 21 [38400/60000 (64%)]\tLoss: 0.045836, Accuracy: 38088/60000 (63%)\n",
      "Train Epoch: 21 [44800/60000 (75%)]\tLoss: 0.011299, Accuracy: 44414/60000 (74%)\n",
      "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 0.066853, Accuracy: 50742/60000 (85%)\n",
      "Train Epoch: 21 [57600/60000 (96%)]\tLoss: 0.051801, Accuracy: 57073/60000 (95%)\n",
      "\n",
      "Test set: Avg. loss: 0.0754, Accuracy: 9764/10000 (98%)\n",
      "\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 0.018197, Accuracy: 64/60000 (0%)\n",
      "Train Epoch: 22 [6400/60000 (11%)]\tLoss: 0.044884, Accuracy: 6392/60000 (11%)\n",
      "Train Epoch: 22 [12800/60000 (21%)]\tLoss: 0.012781, Accuracy: 12749/60000 (21%)\n",
      "Train Epoch: 22 [19200/60000 (32%)]\tLoss: 0.051698, Accuracy: 19085/60000 (32%)\n",
      "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 0.017122, Accuracy: 25424/60000 (42%)\n",
      "Train Epoch: 22 [32000/60000 (53%)]\tLoss: 0.025339, Accuracy: 31774/60000 (53%)\n",
      "Train Epoch: 22 [38400/60000 (64%)]\tLoss: 0.045091, Accuracy: 38116/60000 (64%)\n",
      "Train Epoch: 22 [44800/60000 (75%)]\tLoss: 0.022158, Accuracy: 44456/60000 (74%)\n",
      "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 0.005383, Accuracy: 50801/60000 (85%)\n",
      "Train Epoch: 22 [57600/60000 (96%)]\tLoss: 0.056137, Accuracy: 57120/60000 (95%)\n",
      "\n",
      "Test set: Avg. loss: 0.0731, Accuracy: 9782/10000 (98%)\n",
      "\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 0.018625, Accuracy: 64/60000 (0%)\n",
      "Train Epoch: 23 [6400/60000 (11%)]\tLoss: 0.015959, Accuracy: 6405/60000 (11%)\n",
      "Train Epoch: 23 [12800/60000 (21%)]\tLoss: 0.032252, Accuracy: 12737/60000 (21%)\n",
      "Train Epoch: 23 [19200/60000 (32%)]\tLoss: 0.029234, Accuracy: 19086/60000 (32%)\n",
      "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 0.007098, Accuracy: 25445/60000 (42%)\n",
      "Train Epoch: 23 [32000/60000 (53%)]\tLoss: 0.024245, Accuracy: 31788/60000 (53%)\n",
      "Train Epoch: 23 [38400/60000 (64%)]\tLoss: 0.063902, Accuracy: 38130/60000 (64%)\n",
      "Train Epoch: 23 [44800/60000 (75%)]\tLoss: 0.069104, Accuracy: 44472/60000 (74%)\n",
      "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 0.040583, Accuracy: 50805/60000 (85%)\n",
      "Train Epoch: 23 [57600/60000 (96%)]\tLoss: 0.032277, Accuracy: 57144/60000 (95%)\n",
      "\n",
      "Test set: Avg. loss: 0.0719, Accuracy: 9777/10000 (98%)\n",
      "\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 0.041048, Accuracy: 63/60000 (0%)\n",
      "Train Epoch: 24 [6400/60000 (11%)]\tLoss: 0.031632, Accuracy: 6406/60000 (11%)\n",
      "Train Epoch: 24 [12800/60000 (21%)]\tLoss: 0.014108, Accuracy: 12752/60000 (21%)\n",
      "Train Epoch: 24 [19200/60000 (32%)]\tLoss: 0.022760, Accuracy: 19094/60000 (32%)\n",
      "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 0.040161, Accuracy: 25437/60000 (42%)\n",
      "Train Epoch: 24 [32000/60000 (53%)]\tLoss: 0.013468, Accuracy: 31792/60000 (53%)\n",
      "Train Epoch: 24 [38400/60000 (64%)]\tLoss: 0.043924, Accuracy: 38134/60000 (64%)\n",
      "Train Epoch: 24 [44800/60000 (75%)]\tLoss: 0.013147, Accuracy: 44494/60000 (74%)\n",
      "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 0.071656, Accuracy: 50842/60000 (85%)\n",
      "Train Epoch: 24 [57600/60000 (96%)]\tLoss: 0.060296, Accuracy: 57187/60000 (95%)\n",
      "\n",
      "Test set: Avg. loss: 0.0723, Accuracy: 9773/10000 (98%)\n",
      "\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 0.011038, Accuracy: 64/60000 (0%)\n",
      "Train Epoch: 25 [6400/60000 (11%)]\tLoss: 0.019635, Accuracy: 6421/60000 (11%)\n",
      "Train Epoch: 25 [12800/60000 (21%)]\tLoss: 0.112849, Accuracy: 12774/60000 (21%)\n",
      "Train Epoch: 25 [19200/60000 (32%)]\tLoss: 0.031099, Accuracy: 19139/60000 (32%)\n",
      "Train Epoch: 25 [25600/60000 (43%)]\tLoss: 0.049047, Accuracy: 25491/60000 (42%)\n",
      "Train Epoch: 25 [32000/60000 (53%)]\tLoss: 0.006046, Accuracy: 31839/60000 (53%)\n",
      "Train Epoch: 25 [38400/60000 (64%)]\tLoss: 0.022435, Accuracy: 38194/60000 (64%)\n",
      "Train Epoch: 25 [44800/60000 (75%)]\tLoss: 0.007568, Accuracy: 44536/60000 (74%)\n",
      "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 0.025650, Accuracy: 50873/60000 (85%)\n",
      "Train Epoch: 25 [57600/60000 (96%)]\tLoss: 0.019606, Accuracy: 57217/60000 (95%)\n",
      "\n",
      "Test set: Avg. loss: 0.0723, Accuracy: 9774/10000 (98%)\n",
      "\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 0.018388, Accuracy: 64/60000 (0%)\n",
      "Train Epoch: 26 [6400/60000 (11%)]\tLoss: 0.013716, Accuracy: 6419/60000 (11%)\n",
      "Train Epoch: 26 [12800/60000 (21%)]\tLoss: 0.027521, Accuracy: 12768/60000 (21%)\n",
      "Train Epoch: 26 [19200/60000 (32%)]\tLoss: 0.010162, Accuracy: 19125/60000 (32%)\n",
      "Train Epoch: 26 [25600/60000 (43%)]\tLoss: 0.016552, Accuracy: 25481/60000 (42%)\n",
      "Train Epoch: 26 [32000/60000 (53%)]\tLoss: 0.042734, Accuracy: 31831/60000 (53%)\n",
      "Train Epoch: 26 [38400/60000 (64%)]\tLoss: 0.027236, Accuracy: 38189/60000 (64%)\n",
      "Train Epoch: 26 [44800/60000 (75%)]\tLoss: 0.023197, Accuracy: 44542/60000 (74%)\n",
      "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 0.079980, Accuracy: 50895/60000 (85%)\n",
      "Train Epoch: 26 [57600/60000 (96%)]\tLoss: 0.020939, Accuracy: 57245/60000 (95%)\n",
      "\n",
      "Test set: Avg. loss: 0.0708, Accuracy: 9776/10000 (98%)\n",
      "\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 0.068724, Accuracy: 62/60000 (0%)\n",
      "Train Epoch: 27 [6400/60000 (11%)]\tLoss: 0.019775, Accuracy: 6425/60000 (11%)\n",
      "Train Epoch: 27 [12800/60000 (21%)]\tLoss: 0.028693, Accuracy: 12787/60000 (21%)\n",
      "Train Epoch: 27 [19200/60000 (32%)]\tLoss: 0.016840, Accuracy: 19137/60000 (32%)\n",
      "Train Epoch: 27 [25600/60000 (43%)]\tLoss: 0.011787, Accuracy: 25507/60000 (43%)\n",
      "Train Epoch: 27 [32000/60000 (53%)]\tLoss: 0.005158, Accuracy: 31869/60000 (53%)\n",
      "Train Epoch: 27 [38400/60000 (64%)]\tLoss: 0.025559, Accuracy: 38229/60000 (64%)\n",
      "Train Epoch: 27 [44800/60000 (75%)]\tLoss: 0.028244, Accuracy: 44573/60000 (74%)\n",
      "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 0.020971, Accuracy: 50933/60000 (85%)\n",
      "Train Epoch: 27 [57600/60000 (96%)]\tLoss: 0.023787, Accuracy: 57282/60000 (95%)\n",
      "\n",
      "Test set: Avg. loss: 0.0736, Accuracy: 9768/10000 (98%)\n",
      "\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 0.078417, Accuracy: 62/60000 (0%)\n",
      "Train Epoch: 28 [6400/60000 (11%)]\tLoss: 0.011573, Accuracy: 6412/60000 (11%)\n",
      "Train Epoch: 28 [12800/60000 (21%)]\tLoss: 0.009717, Accuracy: 12785/60000 (21%)\n",
      "Train Epoch: 28 [19200/60000 (32%)]\tLoss: 0.033929, Accuracy: 19147/60000 (32%)\n",
      "Train Epoch: 28 [25600/60000 (43%)]\tLoss: 0.006699, Accuracy: 25504/60000 (43%)\n",
      "Train Epoch: 28 [32000/60000 (53%)]\tLoss: 0.002605, Accuracy: 31856/60000 (53%)\n",
      "Train Epoch: 28 [38400/60000 (64%)]\tLoss: 0.032646, Accuracy: 38219/60000 (64%)\n",
      "Train Epoch: 28 [44800/60000 (75%)]\tLoss: 0.023892, Accuracy: 44583/60000 (74%)\n",
      "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 0.035766, Accuracy: 50955/60000 (85%)\n",
      "Train Epoch: 28 [57600/60000 (96%)]\tLoss: 0.019307, Accuracy: 57306/60000 (96%)\n",
      "\n",
      "Test set: Avg. loss: 0.0706, Accuracy: 9777/10000 (98%)\n",
      "\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 0.018526, Accuracy: 64/60000 (0%)\n",
      "Train Epoch: 29 [6400/60000 (11%)]\tLoss: 0.007979, Accuracy: 6427/60000 (11%)\n",
      "Train Epoch: 29 [12800/60000 (21%)]\tLoss: 0.004204, Accuracy: 12779/60000 (21%)\n",
      "Train Epoch: 29 [19200/60000 (32%)]\tLoss: 0.027373, Accuracy: 19145/60000 (32%)\n",
      "Train Epoch: 29 [25600/60000 (43%)]\tLoss: 0.016207, Accuracy: 25500/60000 (42%)\n",
      "Train Epoch: 29 [32000/60000 (53%)]\tLoss: 0.027091, Accuracy: 31881/60000 (53%)\n",
      "Train Epoch: 29 [38400/60000 (64%)]\tLoss: 0.014383, Accuracy: 38242/60000 (64%)\n",
      "Train Epoch: 29 [44800/60000 (75%)]\tLoss: 0.021339, Accuracy: 44596/60000 (74%)\n",
      "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 0.085853, Accuracy: 50955/60000 (85%)\n",
      "Train Epoch: 29 [57600/60000 (96%)]\tLoss: 0.045570, Accuracy: 57316/60000 (96%)\n",
      "\n",
      "Test set: Avg. loss: 0.0730, Accuracy: 9772/10000 (98%)\n",
      "\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 0.018721, Accuracy: 64/60000 (0%)\n",
      "Train Epoch: 30 [6400/60000 (11%)]\tLoss: 0.011711, Accuracy: 6434/60000 (11%)\n",
      "Train Epoch: 30 [12800/60000 (21%)]\tLoss: 0.033293, Accuracy: 12801/60000 (21%)\n",
      "Train Epoch: 30 [19200/60000 (32%)]\tLoss: 0.055854, Accuracy: 19170/60000 (32%)\n",
      "Train Epoch: 30 [25600/60000 (43%)]\tLoss: 0.010865, Accuracy: 25526/60000 (43%)\n",
      "Train Epoch: 30 [32000/60000 (53%)]\tLoss: 0.028765, Accuracy: 31888/60000 (53%)\n",
      "Train Epoch: 30 [38400/60000 (64%)]\tLoss: 0.036656, Accuracy: 38256/60000 (64%)\n",
      "Train Epoch: 30 [44800/60000 (75%)]\tLoss: 0.008403, Accuracy: 44627/60000 (74%)\n",
      "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 0.020028, Accuracy: 50983/60000 (85%)\n",
      "Train Epoch: 30 [57600/60000 (96%)]\tLoss: 0.021974, Accuracy: 57342/60000 (96%)\n",
      "\n",
      "Test set: Avg. loss: 0.0703, Accuracy: 9780/10000 (98%)\n",
      "\n",
      "Train Epoch: 31 [0/60000 (0%)]\tLoss: 0.019932, Accuracy: 64/60000 (0%)\n",
      "Train Epoch: 31 [6400/60000 (11%)]\tLoss: 0.071356, Accuracy: 6429/60000 (11%)\n",
      "Train Epoch: 31 [12800/60000 (21%)]\tLoss: 0.011970, Accuracy: 12807/60000 (21%)\n",
      "Train Epoch: 31 [19200/60000 (32%)]\tLoss: 0.012101, Accuracy: 19175/60000 (32%)\n",
      "Train Epoch: 31 [25600/60000 (43%)]\tLoss: 0.026456, Accuracy: 25536/60000 (43%)\n",
      "Train Epoch: 31 [32000/60000 (53%)]\tLoss: 0.026802, Accuracy: 31911/60000 (53%)\n",
      "Train Epoch: 31 [38400/60000 (64%)]\tLoss: 0.015161, Accuracy: 38289/60000 (64%)\n",
      "Train Epoch: 31 [44800/60000 (75%)]\tLoss: 0.028369, Accuracy: 44656/60000 (74%)\n",
      "Train Epoch: 31 [51200/60000 (85%)]\tLoss: 0.020816, Accuracy: 51023/60000 (85%)\n",
      "Train Epoch: 31 [57600/60000 (96%)]\tLoss: 0.014628, Accuracy: 57372/60000 (96%)\n",
      "\n",
      "Test set: Avg. loss: 0.0704, Accuracy: 9786/10000 (98%)\n",
      "\n",
      "Train Epoch: 32 [0/60000 (0%)]\tLoss: 0.006459, Accuracy: 64/60000 (0%)\n",
      "Train Epoch: 32 [6400/60000 (11%)]\tLoss: 0.019461, Accuracy: 6442/60000 (11%)\n",
      "Train Epoch: 32 [12800/60000 (21%)]\tLoss: 0.051294, Accuracy: 12810/60000 (21%)\n",
      "Train Epoch: 32 [19200/60000 (32%)]\tLoss: 0.040126, Accuracy: 19189/60000 (32%)\n",
      "Train Epoch: 32 [25600/60000 (43%)]\tLoss: 0.007475, Accuracy: 25562/60000 (43%)\n",
      "Train Epoch: 32 [32000/60000 (53%)]\tLoss: 0.021391, Accuracy: 31930/60000 (53%)\n",
      "Train Epoch: 32 [38400/60000 (64%)]\tLoss: 0.002688, Accuracy: 38301/60000 (64%)\n",
      "Train Epoch: 32 [44800/60000 (75%)]\tLoss: 0.030816, Accuracy: 44661/60000 (74%)\n",
      "Train Epoch: 32 [51200/60000 (85%)]\tLoss: 0.027255, Accuracy: 51032/60000 (85%)\n",
      "Train Epoch: 32 [57600/60000 (96%)]\tLoss: 0.025346, Accuracy: 57395/60000 (96%)\n",
      "\n",
      "Test set: Avg. loss: 0.0702, Accuracy: 9785/10000 (98%)\n",
      "\n",
      "Train Epoch: 33 [0/60000 (0%)]\tLoss: 0.004491, Accuracy: 64/60000 (0%)\n",
      "Train Epoch: 33 [6400/60000 (11%)]\tLoss: 0.042574, Accuracy: 6438/60000 (11%)\n",
      "Train Epoch: 33 [12800/60000 (21%)]\tLoss: 0.010187, Accuracy: 12811/60000 (21%)\n",
      "Train Epoch: 33 [19200/60000 (32%)]\tLoss: 0.014562, Accuracy: 19190/60000 (32%)\n",
      "Train Epoch: 33 [25600/60000 (43%)]\tLoss: 0.028018, Accuracy: 25571/60000 (43%)\n",
      "Train Epoch: 33 [32000/60000 (53%)]\tLoss: 0.005049, Accuracy: 31954/60000 (53%)\n",
      "Train Epoch: 33 [38400/60000 (64%)]\tLoss: 0.012447, Accuracy: 38329/60000 (64%)\n",
      "Train Epoch: 33 [44800/60000 (75%)]\tLoss: 0.006823, Accuracy: 44683/60000 (74%)\n",
      "Train Epoch: 33 [51200/60000 (85%)]\tLoss: 0.008880, Accuracy: 51053/60000 (85%)\n",
      "Train Epoch: 33 [57600/60000 (96%)]\tLoss: 0.024287, Accuracy: 57415/60000 (96%)\n",
      "\n",
      "Test set: Avg. loss: 0.0709, Accuracy: 9787/10000 (98%)\n",
      "\n",
      "Train Epoch: 34 [0/60000 (0%)]\tLoss: 0.015721, Accuracy: 64/60000 (0%)\n",
      "Train Epoch: 34 [6400/60000 (11%)]\tLoss: 0.019858, Accuracy: 6447/60000 (11%)\n",
      "Train Epoch: 34 [12800/60000 (21%)]\tLoss: 0.059424, Accuracy: 12818/60000 (21%)\n",
      "Train Epoch: 34 [19200/60000 (32%)]\tLoss: 0.009272, Accuracy: 19201/60000 (32%)\n",
      "Train Epoch: 34 [25600/60000 (43%)]\tLoss: 0.026370, Accuracy: 25583/60000 (43%)\n",
      "Train Epoch: 34 [32000/60000 (53%)]\tLoss: 0.046835, Accuracy: 31967/60000 (53%)\n",
      "Train Epoch: 34 [38400/60000 (64%)]\tLoss: 0.013018, Accuracy: 38327/60000 (64%)\n",
      "Train Epoch: 34 [44800/60000 (75%)]\tLoss: 0.004540, Accuracy: 44697/60000 (74%)\n",
      "Train Epoch: 34 [51200/60000 (85%)]\tLoss: 0.015876, Accuracy: 51072/60000 (85%)\n",
      "Train Epoch: 34 [57600/60000 (96%)]\tLoss: 0.044565, Accuracy: 57440/60000 (96%)\n",
      "\n",
      "Test set: Avg. loss: 0.0694, Accuracy: 9789/10000 (98%)\n",
      "\n",
      "Train Epoch: 35 [0/60000 (0%)]\tLoss: 0.020369, Accuracy: 64/60000 (0%)\n",
      "Train Epoch: 35 [6400/60000 (11%)]\tLoss: 0.032195, Accuracy: 6447/60000 (11%)\n",
      "Train Epoch: 35 [12800/60000 (21%)]\tLoss: 0.010532, Accuracy: 12826/60000 (21%)\n",
      "Train Epoch: 35 [19200/60000 (32%)]\tLoss: 0.004314, Accuracy: 19206/60000 (32%)\n",
      "Train Epoch: 35 [25600/60000 (43%)]\tLoss: 0.036054, Accuracy: 25588/60000 (43%)\n",
      "Train Epoch: 35 [32000/60000 (53%)]\tLoss: 0.006549, Accuracy: 31966/60000 (53%)\n",
      "Train Epoch: 35 [38400/60000 (64%)]\tLoss: 0.014145, Accuracy: 38347/60000 (64%)\n",
      "Train Epoch: 35 [44800/60000 (75%)]\tLoss: 0.016694, Accuracy: 44722/60000 (75%)\n",
      "Train Epoch: 35 [51200/60000 (85%)]\tLoss: 0.014409, Accuracy: 51099/60000 (85%)\n",
      "Train Epoch: 35 [57600/60000 (96%)]\tLoss: 0.013440, Accuracy: 57468/60000 (96%)\n",
      "\n",
      "Test set: Avg. loss: 0.0701, Accuracy: 9785/10000 (98%)\n",
      "\n",
      "Train Epoch: 36 [0/60000 (0%)]\tLoss: 0.014671, Accuracy: 64/60000 (0%)\n",
      "Train Epoch: 36 [6400/60000 (11%)]\tLoss: 0.004404, Accuracy: 6440/60000 (11%)\n",
      "Train Epoch: 36 [12800/60000 (21%)]\tLoss: 0.014192, Accuracy: 12816/60000 (21%)\n",
      "Train Epoch: 36 [19200/60000 (32%)]\tLoss: 0.043183, Accuracy: 19196/60000 (32%)\n",
      "Train Epoch: 36 [25600/60000 (43%)]\tLoss: 0.008683, Accuracy: 25576/60000 (43%)\n",
      "Train Epoch: 36 [32000/60000 (53%)]\tLoss: 0.008743, Accuracy: 31955/60000 (53%)\n",
      "Train Epoch: 36 [38400/60000 (64%)]\tLoss: 0.074451, Accuracy: 38339/60000 (64%)\n",
      "Train Epoch: 36 [44800/60000 (75%)]\tLoss: 0.002764, Accuracy: 44714/60000 (75%)\n",
      "Train Epoch: 36 [51200/60000 (85%)]\tLoss: 0.018700, Accuracy: 51100/60000 (85%)\n",
      "Train Epoch: 36 [57600/60000 (96%)]\tLoss: 0.055928, Accuracy: 57476/60000 (96%)\n",
      "\n",
      "Test set: Avg. loss: 0.0694, Accuracy: 9794/10000 (98%)\n",
      "\n",
      "Train Epoch: 37 [0/60000 (0%)]\tLoss: 0.005954, Accuracy: 64/60000 (0%)\n",
      "Train Epoch: 37 [6400/60000 (11%)]\tLoss: 0.007525, Accuracy: 6449/60000 (11%)\n",
      "Train Epoch: 37 [12800/60000 (21%)]\tLoss: 0.008372, Accuracy: 12835/60000 (21%)\n",
      "Train Epoch: 37 [19200/60000 (32%)]\tLoss: 0.019796, Accuracy: 19220/60000 (32%)\n",
      "Train Epoch: 37 [25600/60000 (43%)]\tLoss: 0.039090, Accuracy: 25606/60000 (43%)\n",
      "Train Epoch: 37 [32000/60000 (53%)]\tLoss: 0.031564, Accuracy: 31980/60000 (53%)\n",
      "Train Epoch: 37 [38400/60000 (64%)]\tLoss: 0.003310, Accuracy: 38362/60000 (64%)\n",
      "Train Epoch: 37 [44800/60000 (75%)]\tLoss: 0.010099, Accuracy: 44739/60000 (75%)\n",
      "Train Epoch: 37 [51200/60000 (85%)]\tLoss: 0.031211, Accuracy: 51116/60000 (85%)\n",
      "Train Epoch: 37 [57600/60000 (96%)]\tLoss: 0.010848, Accuracy: 57486/60000 (96%)\n",
      "\n",
      "Test set: Avg. loss: 0.0699, Accuracy: 9786/10000 (98%)\n",
      "\n",
      "Train Epoch: 38 [0/60000 (0%)]\tLoss: 0.018930, Accuracy: 64/60000 (0%)\n",
      "Train Epoch: 38 [6400/60000 (11%)]\tLoss: 0.007334, Accuracy: 6447/60000 (11%)\n",
      "Train Epoch: 38 [12800/60000 (21%)]\tLoss: 0.009654, Accuracy: 12835/60000 (21%)\n",
      "Train Epoch: 38 [19200/60000 (32%)]\tLoss: 0.020705, Accuracy: 19222/60000 (32%)\n",
      "Train Epoch: 38 [25600/60000 (43%)]\tLoss: 0.006443, Accuracy: 25609/60000 (43%)\n",
      "Train Epoch: 38 [32000/60000 (53%)]\tLoss: 0.028087, Accuracy: 31995/60000 (53%)\n",
      "Train Epoch: 38 [38400/60000 (64%)]\tLoss: 0.020884, Accuracy: 38376/60000 (64%)\n",
      "Train Epoch: 38 [44800/60000 (75%)]\tLoss: 0.006261, Accuracy: 44756/60000 (75%)\n",
      "Train Epoch: 38 [51200/60000 (85%)]\tLoss: 0.009717, Accuracy: 51141/60000 (85%)\n",
      "Train Epoch: 38 [57600/60000 (96%)]\tLoss: 0.032492, Accuracy: 57518/60000 (96%)\n",
      "\n",
      "Test set: Avg. loss: 0.0701, Accuracy: 9776/10000 (98%)\n",
      "\n",
      "Train Epoch: 39 [0/60000 (0%)]\tLoss: 0.008868, Accuracy: 64/60000 (0%)\n",
      "Train Epoch: 39 [6400/60000 (11%)]\tLoss: 0.011002, Accuracy: 6454/60000 (11%)\n",
      "Train Epoch: 39 [12800/60000 (21%)]\tLoss: 0.053780, Accuracy: 12837/60000 (21%)\n",
      "Train Epoch: 39 [19200/60000 (32%)]\tLoss: 0.010724, Accuracy: 19215/60000 (32%)\n",
      "Train Epoch: 39 [25600/60000 (43%)]\tLoss: 0.002909, Accuracy: 25601/60000 (43%)\n",
      "Train Epoch: 39 [32000/60000 (53%)]\tLoss: 0.035763, Accuracy: 31982/60000 (53%)\n",
      "Train Epoch: 39 [38400/60000 (64%)]\tLoss: 0.007564, Accuracy: 38372/60000 (64%)\n",
      "Train Epoch: 39 [44800/60000 (75%)]\tLoss: 0.034155, Accuracy: 44754/60000 (75%)\n",
      "Train Epoch: 39 [51200/60000 (85%)]\tLoss: 0.014200, Accuracy: 51131/60000 (85%)\n",
      "Train Epoch: 39 [57600/60000 (96%)]\tLoss: 0.074724, Accuracy: 57514/60000 (96%)\n",
      "\n",
      "Test set: Avg. loss: 0.0698, Accuracy: 9785/10000 (98%)\n",
      "\n",
      "Train Epoch: 40 [0/60000 (0%)]\tLoss: 0.004892, Accuracy: 64/60000 (0%)\n",
      "Train Epoch: 40 [6400/60000 (11%)]\tLoss: 0.009430, Accuracy: 6456/60000 (11%)\n",
      "Train Epoch: 40 [12800/60000 (21%)]\tLoss: 0.026535, Accuracy: 12842/60000 (21%)\n",
      "Train Epoch: 40 [19200/60000 (32%)]\tLoss: 0.008888, Accuracy: 19227/60000 (32%)\n",
      "Train Epoch: 40 [25600/60000 (43%)]\tLoss: 0.010177, Accuracy: 25605/60000 (43%)\n",
      "Train Epoch: 40 [32000/60000 (53%)]\tLoss: 0.023385, Accuracy: 31994/60000 (53%)\n",
      "Train Epoch: 40 [38400/60000 (64%)]\tLoss: 0.012064, Accuracy: 38379/60000 (64%)\n",
      "Train Epoch: 40 [44800/60000 (75%)]\tLoss: 0.014890, Accuracy: 44760/60000 (75%)\n",
      "Train Epoch: 40 [51200/60000 (85%)]\tLoss: 0.009750, Accuracy: 51145/60000 (85%)\n",
      "Train Epoch: 40 [57600/60000 (96%)]\tLoss: 0.012094, Accuracy: 57528/60000 (96%)\n",
      "\n",
      "Test set: Avg. loss: 0.0703, Accuracy: 9788/10000 (98%)\n",
      "\n",
      "Train Epoch: 41 [0/60000 (0%)]\tLoss: 0.016473, Accuracy: 64/60000 (0%)\n",
      "Train Epoch: 41 [6400/60000 (11%)]\tLoss: 0.009366, Accuracy: 6453/60000 (11%)\n",
      "Train Epoch: 41 [12800/60000 (21%)]\tLoss: 0.004475, Accuracy: 12843/60000 (21%)\n",
      "Train Epoch: 41 [19200/60000 (32%)]\tLoss: 0.016599, Accuracy: 19230/60000 (32%)\n",
      "Train Epoch: 41 [25600/60000 (43%)]\tLoss: 0.008981, Accuracy: 25611/60000 (43%)\n",
      "Train Epoch: 41 [32000/60000 (53%)]\tLoss: 0.023578, Accuracy: 31992/60000 (53%)\n",
      "Train Epoch: 41 [38400/60000 (64%)]\tLoss: 0.030105, Accuracy: 38378/60000 (64%)\n",
      "Train Epoch: 41 [44800/60000 (75%)]\tLoss: 0.023326, Accuracy: 44766/60000 (75%)\n",
      "Train Epoch: 41 [51200/60000 (85%)]\tLoss: 0.013524, Accuracy: 51151/60000 (85%)\n",
      "Train Epoch: 41 [57600/60000 (96%)]\tLoss: 0.019630, Accuracy: 57535/60000 (96%)\n",
      "\n",
      "Test set: Avg. loss: 0.0701, Accuracy: 9788/10000 (98%)\n",
      "\n",
      "Train Epoch: 42 [0/60000 (0%)]\tLoss: 0.027274, Accuracy: 63/60000 (0%)\n",
      "Train Epoch: 42 [6400/60000 (11%)]\tLoss: 0.006217, Accuracy: 6450/60000 (11%)\n",
      "Train Epoch: 42 [12800/60000 (21%)]\tLoss: 0.016502, Accuracy: 12835/60000 (21%)\n",
      "Train Epoch: 42 [19200/60000 (32%)]\tLoss: 0.017860, Accuracy: 19223/60000 (32%)\n",
      "Train Epoch: 42 [25600/60000 (43%)]\tLoss: 0.013669, Accuracy: 25612/60000 (43%)\n",
      "Train Epoch: 42 [32000/60000 (53%)]\tLoss: 0.006680, Accuracy: 31999/60000 (53%)\n",
      "Train Epoch: 42 [38400/60000 (64%)]\tLoss: 0.014608, Accuracy: 38394/60000 (64%)\n",
      "Train Epoch: 42 [44800/60000 (75%)]\tLoss: 0.009494, Accuracy: 44784/60000 (75%)\n",
      "Train Epoch: 42 [51200/60000 (85%)]\tLoss: 0.026728, Accuracy: 51175/60000 (85%)\n",
      "Train Epoch: 42 [57600/60000 (96%)]\tLoss: 0.005155, Accuracy: 57558/60000 (96%)\n",
      "\n",
      "Test set: Avg. loss: 0.0710, Accuracy: 9785/10000 (98%)\n",
      "\n",
      "Train Epoch: 43 [0/60000 (0%)]\tLoss: 0.015656, Accuracy: 64/60000 (0%)\n",
      "Train Epoch: 43 [6400/60000 (11%)]\tLoss: 0.004710, Accuracy: 6454/60000 (11%)\n",
      "Train Epoch: 43 [12800/60000 (21%)]\tLoss: 0.006911, Accuracy: 12847/60000 (21%)\n",
      "Train Epoch: 43 [19200/60000 (32%)]\tLoss: 0.006452, Accuracy: 19230/60000 (32%)\n",
      "Train Epoch: 43 [25600/60000 (43%)]\tLoss: 0.008648, Accuracy: 25620/60000 (43%)\n",
      "Train Epoch: 43 [32000/60000 (53%)]\tLoss: 0.013524, Accuracy: 32011/60000 (53%)\n",
      "Train Epoch: 43 [38400/60000 (64%)]\tLoss: 0.003950, Accuracy: 38396/60000 (64%)\n",
      "Train Epoch: 43 [44800/60000 (75%)]\tLoss: 0.008803, Accuracy: 44780/60000 (75%)\n",
      "Train Epoch: 43 [51200/60000 (85%)]\tLoss: 0.028456, Accuracy: 51164/60000 (85%)\n",
      "Train Epoch: 43 [57600/60000 (96%)]\tLoss: 0.020181, Accuracy: 57554/60000 (96%)\n",
      "\n",
      "Test set: Avg. loss: 0.0710, Accuracy: 9787/10000 (98%)\n",
      "\n",
      "Train Epoch: 44 [0/60000 (0%)]\tLoss: 0.024998, Accuracy: 64/60000 (0%)\n",
      "Train Epoch: 44 [6400/60000 (11%)]\tLoss: 0.022983, Accuracy: 6451/60000 (11%)\n",
      "Train Epoch: 44 [12800/60000 (21%)]\tLoss: 0.002241, Accuracy: 12838/60000 (21%)\n",
      "Train Epoch: 44 [19200/60000 (32%)]\tLoss: 0.023958, Accuracy: 19224/60000 (32%)\n",
      "Train Epoch: 44 [25600/60000 (43%)]\tLoss: 0.011256, Accuracy: 25612/60000 (43%)\n",
      "Train Epoch: 44 [32000/60000 (53%)]\tLoss: 0.007888, Accuracy: 32004/60000 (53%)\n",
      "Train Epoch: 44 [38400/60000 (64%)]\tLoss: 0.014266, Accuracy: 38393/60000 (64%)\n",
      "Train Epoch: 44 [44800/60000 (75%)]\tLoss: 0.018039, Accuracy: 44780/60000 (75%)\n",
      "Train Epoch: 44 [51200/60000 (85%)]\tLoss: 0.004780, Accuracy: 51172/60000 (85%)\n",
      "Train Epoch: 44 [57600/60000 (96%)]\tLoss: 0.008935, Accuracy: 57558/60000 (96%)\n",
      "\n",
      "Test set: Avg. loss: 0.0701, Accuracy: 9789/10000 (98%)\n",
      "\n",
      "Train Epoch: 45 [0/60000 (0%)]\tLoss: 0.002679, Accuracy: 64/60000 (0%)\n",
      "Train Epoch: 45 [6400/60000 (11%)]\tLoss: 0.007351, Accuracy: 6455/60000 (11%)\n",
      "Train Epoch: 45 [12800/60000 (21%)]\tLoss: 0.013519, Accuracy: 12848/60000 (21%)\n",
      "Train Epoch: 45 [19200/60000 (32%)]\tLoss: 0.009929, Accuracy: 19240/60000 (32%)\n",
      "Train Epoch: 45 [25600/60000 (43%)]\tLoss: 0.005166, Accuracy: 25632/60000 (43%)\n",
      "Train Epoch: 45 [32000/60000 (53%)]\tLoss: 0.004843, Accuracy: 32024/60000 (53%)\n",
      "Train Epoch: 45 [38400/60000 (64%)]\tLoss: 0.019814, Accuracy: 38409/60000 (64%)\n",
      "Train Epoch: 45 [44800/60000 (75%)]\tLoss: 0.014218, Accuracy: 44796/60000 (75%)\n",
      "Train Epoch: 45 [51200/60000 (85%)]\tLoss: 0.006944, Accuracy: 51178/60000 (85%)\n",
      "Train Epoch: 45 [57600/60000 (96%)]\tLoss: 0.012784, Accuracy: 57568/60000 (96%)\n",
      "\n",
      "Test set: Avg. loss: 0.0696, Accuracy: 9791/10000 (98%)\n",
      "\n",
      "Train Epoch: 46 [0/60000 (0%)]\tLoss: 0.003764, Accuracy: 64/60000 (0%)\n",
      "Train Epoch: 46 [6400/60000 (11%)]\tLoss: 0.004840, Accuracy: 6456/60000 (11%)\n",
      "Train Epoch: 46 [12800/60000 (21%)]\tLoss: 0.013652, Accuracy: 12843/60000 (21%)\n",
      "Train Epoch: 46 [19200/60000 (32%)]\tLoss: 0.013798, Accuracy: 19236/60000 (32%)\n",
      "Train Epoch: 46 [25600/60000 (43%)]\tLoss: 0.002570, Accuracy: 25630/60000 (43%)\n",
      "Train Epoch: 46 [32000/60000 (53%)]\tLoss: 0.014961, Accuracy: 32022/60000 (53%)\n",
      "Train Epoch: 46 [38400/60000 (64%)]\tLoss: 0.012974, Accuracy: 38412/60000 (64%)\n",
      "Train Epoch: 46 [44800/60000 (75%)]\tLoss: 0.018052, Accuracy: 44805/60000 (75%)\n",
      "Train Epoch: 46 [51200/60000 (85%)]\tLoss: 0.007993, Accuracy: 51191/60000 (85%)\n",
      "Train Epoch: 46 [57600/60000 (96%)]\tLoss: 0.008568, Accuracy: 57584/60000 (96%)\n",
      "\n",
      "Test set: Avg. loss: 0.0729, Accuracy: 9776/10000 (98%)\n",
      "\n",
      "Train Epoch: 47 [0/60000 (0%)]\tLoss: 0.010414, Accuracy: 64/60000 (0%)\n",
      "Train Epoch: 47 [6400/60000 (11%)]\tLoss: 0.015126, Accuracy: 6456/60000 (11%)\n",
      "Train Epoch: 47 [12800/60000 (21%)]\tLoss: 0.016895, Accuracy: 12848/60000 (21%)\n",
      "Train Epoch: 47 [19200/60000 (32%)]\tLoss: 0.006247, Accuracy: 19246/60000 (32%)\n",
      "Train Epoch: 47 [25600/60000 (43%)]\tLoss: 0.015806, Accuracy: 25640/60000 (43%)\n",
      "Train Epoch: 47 [32000/60000 (53%)]\tLoss: 0.007825, Accuracy: 32033/60000 (53%)\n",
      "Train Epoch: 47 [38400/60000 (64%)]\tLoss: 0.029458, Accuracy: 38421/60000 (64%)\n",
      "Train Epoch: 47 [44800/60000 (75%)]\tLoss: 0.012633, Accuracy: 44807/60000 (75%)\n",
      "Train Epoch: 47 [51200/60000 (85%)]\tLoss: 0.002203, Accuracy: 51196/60000 (85%)\n",
      "Train Epoch: 47 [57600/60000 (96%)]\tLoss: 0.010380, Accuracy: 57588/60000 (96%)\n",
      "\n",
      "Test set: Avg. loss: 0.0698, Accuracy: 9792/10000 (98%)\n",
      "\n",
      "Train Epoch: 48 [0/60000 (0%)]\tLoss: 0.012908, Accuracy: 64/60000 (0%)\n",
      "Train Epoch: 48 [6400/60000 (11%)]\tLoss: 0.003145, Accuracy: 6456/60000 (11%)\n",
      "Train Epoch: 48 [12800/60000 (21%)]\tLoss: 0.009429, Accuracy: 12851/60000 (21%)\n",
      "Train Epoch: 48 [19200/60000 (32%)]\tLoss: 0.006164, Accuracy: 19247/60000 (32%)\n",
      "Train Epoch: 48 [25600/60000 (43%)]\tLoss: 0.008893, Accuracy: 25638/60000 (43%)\n",
      "Train Epoch: 48 [32000/60000 (53%)]\tLoss: 0.018145, Accuracy: 32032/60000 (53%)\n",
      "Train Epoch: 48 [38400/60000 (64%)]\tLoss: 0.006804, Accuracy: 38425/60000 (64%)\n",
      "Train Epoch: 48 [44800/60000 (75%)]\tLoss: 0.008680, Accuracy: 44820/60000 (75%)\n",
      "Train Epoch: 48 [51200/60000 (85%)]\tLoss: 0.012755, Accuracy: 51211/60000 (85%)\n",
      "Train Epoch: 48 [57600/60000 (96%)]\tLoss: 0.003680, Accuracy: 57598/60000 (96%)\n",
      "\n",
      "Test set: Avg. loss: 0.0701, Accuracy: 9787/10000 (98%)\n",
      "\n",
      "Train Epoch: 49 [0/60000 (0%)]\tLoss: 0.010745, Accuracy: 64/60000 (0%)\n",
      "Train Epoch: 49 [6400/60000 (11%)]\tLoss: 0.010178, Accuracy: 6460/60000 (11%)\n",
      "Train Epoch: 49 [12800/60000 (21%)]\tLoss: 0.019006, Accuracy: 12856/60000 (21%)\n",
      "Train Epoch: 49 [19200/60000 (32%)]\tLoss: 0.013300, Accuracy: 19247/60000 (32%)\n",
      "Train Epoch: 49 [25600/60000 (43%)]\tLoss: 0.016701, Accuracy: 25635/60000 (43%)\n",
      "Train Epoch: 49 [32000/60000 (53%)]\tLoss: 0.001242, Accuracy: 32029/60000 (53%)\n",
      "Train Epoch: 49 [38400/60000 (64%)]\tLoss: 0.004697, Accuracy: 38424/60000 (64%)\n",
      "Train Epoch: 49 [44800/60000 (75%)]\tLoss: 0.001495, Accuracy: 44818/60000 (75%)\n",
      "Train Epoch: 49 [51200/60000 (85%)]\tLoss: 0.011198, Accuracy: 51209/60000 (85%)\n",
      "Train Epoch: 49 [57600/60000 (96%)]\tLoss: 0.008471, Accuracy: 57602/60000 (96%)\n",
      "\n",
      "Test set: Avg. loss: 0.0714, Accuracy: 9790/10000 (98%)\n",
      "\n",
      "Train Epoch: 50 [0/60000 (0%)]\tLoss: 0.012750, Accuracy: 64/60000 (0%)\n",
      "Train Epoch: 50 [6400/60000 (11%)]\tLoss: 0.027034, Accuracy: 6456/60000 (11%)\n",
      "Train Epoch: 50 [12800/60000 (21%)]\tLoss: 0.007045, Accuracy: 12850/60000 (21%)\n",
      "Train Epoch: 50 [19200/60000 (32%)]\tLoss: 0.016330, Accuracy: 19246/60000 (32%)\n",
      "Train Epoch: 50 [25600/60000 (43%)]\tLoss: 0.006248, Accuracy: 25638/60000 (43%)\n",
      "Train Epoch: 50 [32000/60000 (53%)]\tLoss: 0.011229, Accuracy: 32027/60000 (53%)\n",
      "Train Epoch: 50 [38400/60000 (64%)]\tLoss: 0.013444, Accuracy: 38422/60000 (64%)\n",
      "Train Epoch: 50 [44800/60000 (75%)]\tLoss: 0.007447, Accuracy: 44815/60000 (75%)\n",
      "Train Epoch: 50 [51200/60000 (85%)]\tLoss: 0.007257, Accuracy: 51207/60000 (85%)\n",
      "Train Epoch: 50 [57600/60000 (96%)]\tLoss: 0.011529, Accuracy: 57601/60000 (96%)\n",
      "\n",
      "Test set: Avg. loss: 0.0709, Accuracy: 9792/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('device:', device)\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'negative log likelihood loss (losses)')"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_counter, train_losses, color='blue')\n",
    "plt.scatter(test_counter, test_losses, color='red')\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen (counter)')\n",
    "plt.ylabel('negative log likelihood loss (losses)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5 \n",
    "- Find out how the model can be trained on the GPU instead of the CPU. \n",
    "- Compare the training time between CPU and GPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.004993, Accuracy: 64/60000 (0%)\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.004429, Accuracy: 6461/60000 (11%)\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.006418, Accuracy: 12852/60000 (21%)\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.013496, Accuracy: 19245/60000 (32%)\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.006464, Accuracy: 25638/60000 (43%)\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.037968, Accuracy: 32030/60000 (53%)\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.012816, Accuracy: 38426/60000 (64%)\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.022538, Accuracy: 44821/60000 (75%)\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.006768, Accuracy: 51217/60000 (85%)\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.009617, Accuracy: 57610/60000 (96%)\n",
      "CPU time:  4.664626121520996\n",
      "device: mps\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.006593, Accuracy: 64/60000 (0%)\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.013708, Accuracy: 6463/60000 (11%)\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.012040, Accuracy: 12859/60000 (21%)\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.010882, Accuracy: 19255/60000 (32%)\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.008782, Accuracy: 25651/60000 (43%)\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.021183, Accuracy: 32046/60000 (53%)\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.043652, Accuracy: 38436/60000 (64%)\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.019073, Accuracy: 44829/60000 (75%)\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.009391, Accuracy: 51223/60000 (85%)\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.020633, Accuracy: 57617/60000 (96%)\n",
      "GPU time:  5.684415102005005\n"
     ]
    }
   ],
   "source": [
    "# using cpu to train the model\n",
    "# current time \n",
    "import time\n",
    "device = torch.device(\"cpu\") # set the device to be cpu\n",
    "print('device:', device)\n",
    "start_time = time.time()\n",
    "train(1)\n",
    "time_cpu = time.time()\n",
    "print (\"CPU time: \", time_cpu - start_time)\n",
    "\n",
    "# using gpu to train the model\n",
    "device = torch.device(\"mps\") # set the device to be MPS for mac os \n",
    "print('device:', device)\n",
    "start_time = time.time()\n",
    "train(1)\n",
    "time_gpu = time.time()\n",
    "\n",
    "# compare the time difference\n",
    "print (\"GPU time: \", time_gpu - start_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
